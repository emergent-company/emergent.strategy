# Migration Guide: v2.7.x → v2.8.x

> **Migration Type**: MINOR  
> **Estimated Effort**: 30-60 minutes per roadmap  
> **Breaking Changes**: No - new optional fields

## Overview

EPF v2.8.x introduces Technology Readiness Level (TRL) tracking and hypothesis testing fields to roadmap artifacts. These fields enable learning-oriented development and innovation maturity tracking. All new fields are **optional** - existing roadmaps remain valid without changes.

## New Fields Summary

| Field | Location | Purpose | Effort to Add |
|-------|----------|---------|---------------|
| `trl_start` | Key Results | Current TRL level (1-9) | LOW - numeric |
| `trl_target` | Key Results | Target TRL by end of cycle | LOW - numeric |
| `trl_progression` | Key Results | TRL milestones with dates | MEDIUM - array |
| `technical_hypothesis` | Key Results | What we're trying to learn | MEDIUM - text |
| `success_criteria` | Assumptions | How we measure success | MEDIUM - array |
| `uncertainty_addressed` | Assumptions | Knowledge gap being resolved | LOW - text |
| `experiment_design` | Assumptions | How to test the assumption | MEDIUM - text |

---

## When to Add These Fields

### Add TRL Fields When:
- ✅ Key Result involves new technology or architecture
- ✅ Significant uncertainty about feasibility
- ✅ R&D or innovation work
- ✅ Technical proof-of-concept needed
- ✅ Integration with unknown external systems

### Skip TRL Fields When:
- ⏭️ Key Result is process/operational improvement
- ⏭️ Technology is well-established internally
- ⏭️ Pure business/commercial work (use hypothesis fields instead)

### Add Hypothesis Fields When:
- ✅ Assumption has measurable validation criteria
- ✅ Learning/discovery is as important as delivery
- ✅ Pivot decisions depend on assumption validation
- ✅ Market or user behavior uncertainty

---

## Change 1: TRL Fields on Key Results {#trl}

### Schema Addition

```yaml
# In roadmap_recipe_schema.json, Key Results now support:
trl_start:
  type: integer
  minimum: 1
  maximum: 9
  description: "Current Technology Readiness Level"

trl_target:
  type: integer
  minimum: 1
  maximum: 9
  description: "Target TRL by end of cycle"

trl_progression:
  type: array
  items:
    type: object
    properties:
      level: { type: integer, minimum: 1, maximum: 9 }
      target_date: { type: string, format: date }
      milestone: { type: string }
      evidence_required: { type: string }

technical_hypothesis:
  type: string
  description: "What we're trying to learn/prove"
```

### Before (v2.7.x)

```yaml
tracks:
  product:
    okrs:
      - objective: "Establish AI-powered document processing"
        key_results:
          - id: "kr-p-1"
            description: "Deploy ML pipeline processing 1000 docs/day"
            metrics:
              - metric: "Documents processed per day"
                baseline: 0
                target: 1000
```

### After (v2.8.x)

```yaml
tracks:
  product:
    okrs:
      - objective: "Establish AI-powered document processing"
        key_results:
          - id: "kr-p-1"
            description: "Deploy ML pipeline processing 1000 docs/day"
            metrics:
              - metric: "Documents processed per day"
                baseline: 0
                target: 1000
            
            # NEW: TRL tracking for technical maturity
            trl_start: 3
            trl_target: 7
            trl_progression:
              - level: 4
                target_date: "2025-02-15"
                milestone: "Validated in lab with test dataset"
                evidence_required: "Accuracy >90% on 100 test documents"
              - level: 5
                target_date: "2025-03-15"
                milestone: "Validated with real customer documents"
                evidence_required: "Customer confirms acceptable accuracy"
              - level: 6
                target_date: "2025-04-15"
                milestone: "Prototype deployed to staging"
                evidence_required: "Processing 100 docs/day in staging"
              - level: 7
                target_date: "2025-05-15"
                milestone: "Production-ready system"
                evidence_required: "1000 docs/day sustained for 1 week"
            
            technical_hypothesis: |
              We believe that transformer-based document classification 
              can achieve >90% accuracy on our document types with 
              acceptable latency (<2s per document). This would enable 
              automated processing that currently requires manual review.
```

### TRL Level Reference

| Level | Name | Description | Evidence Example |
|-------|------|-------------|------------------|
| 1 | Basic Research | Scientific principles observed | Literature review, research papers |
| 2 | Concept | Technology concept formulated | Concept document, feasibility analysis |
| 3 | Proof of Concept | Analytical/experimental PoC | Working prototype in controlled environment |
| 4 | Lab Validation | Validated in laboratory | Test results with synthetic data |
| 5 | Relevant Environment | Validated with real data | Customer data validation results |
| 6 | Prototype | System prototype demonstrated | Working system in staging |
| 7 | Operational | System operational in pilot | Production metrics from limited rollout |
| 8 | Qualified | System complete and qualified | Full production deployment |
| 9 | Proven | System proven in operations | 6+ months production track record |

### AI Instructions for TRL Migration

```
When adding TRL fields to Key Results:

1. IDENTIFY Key Results that involve:
   - New technology or architecture
   - Significant technical uncertainty
   - R&D or innovation work
   - Integration with unfamiliar systems

2. For each identified KR, ASSESS current state:
   - TRL 1-3: Still in research/concept phase
   - TRL 4-5: Validating with data
   - TRL 6-7: Building production system
   - TRL 8-9: Already proven (skip TRL tracking)

3. ADD fields:
   
   trl_start: [1-9 based on current state]
   trl_target: [realistic target for this cycle, usually +2-4 levels]
   
   trl_progression: [array with milestones]
   - Each entry needs: level, target_date, milestone, evidence_required
   - Space milestones ~4-6 weeks apart
   - Evidence should be specific and measurable
   
   technical_hypothesis: [what we're trying to learn]
   - Start with "We believe that..."
   - Include the technology/approach
   - State expected outcome
   - Include why this matters

4. SKIP TRL fields for KRs that are:
   - Pure process improvements
   - Using well-established technology
   - Business/commercial focused (no technical uncertainty)

5. VALIDATE:
   - trl_target > trl_start
   - trl_progression dates are within cycle
   - Each progression level <= trl_target
```

---

## Change 2: Hypothesis Testing on Assumptions {#hypothesis}

### Schema Addition

```yaml
# In roadmap_recipe_schema.json, Assumptions now support:
success_criteria:
  type: array
  items:
    type: string
  description: "Measurable criteria for validation"

uncertainty_addressed:
  type: string
  description: "What knowledge gap this resolves"

experiment_design:
  type: string
  description: "How we'll test this assumption"
```

### Before (v2.7.x)

```yaml
tracks:
  product:
    riskiest_assumptions:
      - id: "asm-p-001"
        assumption: "Users will adopt AI-powered suggestions"
        linked_to_kr: "kr-p-1"
        validation_approach: "User testing"
        current_confidence: "medium"
```

### After (v2.8.x)

```yaml
tracks:
  product:
    riskiest_assumptions:
      - id: "asm-p-001"
        assumption: "Users will adopt AI-powered suggestions"
        linked_to_kr: "kr-p-1"
        validation_approach: "User testing"
        current_confidence: "medium"
        
        # NEW: Hypothesis testing fields
        success_criteria:
          - "60% of users interact with suggestions within first week"
          - "NPS score for suggestion feature >30"
          - "Less than 10% of users disable suggestions"
        
        uncertainty_addressed: |
          We don't know if users will trust and adopt AI suggestions 
          in their workflow, or if they'll find them intrusive and 
          disable the feature. This uncertainty affects our entire 
          AI product strategy.
        
        experiment_design: |
          1. Deploy to 100-user cohort with suggestions enabled
          2. Track: interaction rate, dismissal rate, disable rate
          3. Send NPS survey after 2 weeks of usage
          4. Conduct 5 user interviews from each segment (adopters, 
             occasional users, non-users)
          5. Decision point: If <40% adoption, pivot approach before 
             wider rollout
```

### AI Instructions for Hypothesis Migration

```
When adding hypothesis testing fields to Assumptions:

1. IDENTIFY assumptions that:
   - Have measurable validation criteria
   - Represent significant uncertainty
   - Could trigger pivot decisions

2. ADD fields:

   success_criteria: [array of measurable statements]
   - Each criterion should be specific and measurable
   - Include target numbers/percentages
   - Cover multiple dimensions (adoption, satisfaction, performance)
   
   uncertainty_addressed: [text explaining the knowledge gap]
   - What don't we know?
   - Why does this uncertainty matter?
   - What decisions depend on resolving it?
   
   experiment_design: [text describing validation approach]
   - Specific steps to test the assumption
   - Sample size and duration
   - Decision criteria (when to pivot)

3. SKIP hypothesis fields for assumptions that:
   - Are low-risk or well-understood
   - Have obvious validation (deploy and see)
   - Are dependencies rather than uncertainties

4. VALIDATE:
   - success_criteria has at least 2 items
   - Each criterion is measurable (contains numbers)
   - experiment_design includes decision point
```

---

## Per-Step Validation Checkpoints

**Validate during enrichment, not just at the end. Fail fast - fix errors before proceeding.**

### After Adding TRL Fields

```bash
# Validate after adding TRL fields to Key Results
./scripts/validate-schemas.sh _instances/{product}/READY/05_roadmap_recipe.yaml

# Common validation errors to check:
# - trl_start/trl_target must be integers 1-9 (not strings)
# - trl_progression[].level must be 1-9
# - trl_progression[].target_date must be YYYY-MM-DD format
# - trl_target should be >= trl_start (you progress forward)

# If validation fails, FIX before adding hypothesis fields!
```

### After Adding Hypothesis Fields

```bash
# Validate after adding hypothesis fields to Assumptions
./scripts/validate-schemas.sh _instances/{product}/READY/05_roadmap_recipe.yaml

# Common validation errors to check:
# - success_criteria must be array of strings, not a single string
# - uncertainty_addressed is string, not array
# - All fields must be at correct indentation level
```

### Per-Track Validation (For Large Roadmaps)

If your roadmap has multiple tracks, validate after completing each track:

```bash
# After enriching Product track
./scripts/validate-schemas.sh _instances/{product}/READY/05_roadmap_recipe.yaml
echo "✓ Product track TRL/hypothesis fields valid"

# After enriching Strategy track  
./scripts/validate-schemas.sh _instances/{product}/READY/05_roadmap_recipe.yaml
echo "✓ Strategy track fields valid"

# ... and so on
```

### Validation Status Report

Before considering enrichment complete, confirm:

| Check | Status | Action if Failed |
|-------|--------|------------------|
| Schema validation | PASS ✓ / FAIL ✗ | FIX - don't proceed |
| TRL values in range | 1-9 | Fix out-of-range values |
| Dates valid format | YYYY-MM-DD | Fix date formatting |
| success_criteria is array | [ ] | Convert string to array |

---

## Migration Checklist

### Pre-Migration
- [ ] Identify roadmap files to migrate
- [ ] Review current Key Results for technical work
- [ ] Review assumptions for validation opportunities

### Per Roadmap
- [ ] Add TRL fields to technical Key Results (optional)
- [ ] Add hypothesis fields to key assumptions (optional)
- [ ] Update template_version comment to v2.8.x
- [ ] Validate: `./scripts/validate-schemas.sh {file}`

### Post-Migration
- [ ] Run coverage analysis: `./scripts/analyze-field-coverage.sh`
- [ ] Update `_meta.yaml` migration_history if desired
- [ ] Review AI-generated content for accuracy

---

## Validation

After enrichment, validate:

```bash
# Validate schema compliance
./scripts/validate-schemas.sh _instances/{product}/READY/05_roadmap_recipe.yaml

# Check field coverage (see TRL/hypothesis scores)
./scripts/analyze-field-coverage.sh _instances/{product}/READY/05_roadmap_recipe.yaml
```

### Expected Coverage Improvement

| Before | After | Fields Added |
|--------|-------|--------------|
| ~40% | ~70% | TRL tracking |
| ~50% | ~80% | + Hypothesis testing |

---

## Example: Complete Enhancement

### Before (v2.7.4)

```yaml
# Roadmap Recipe - Product Track
# EPF v2.7.4

tracks:
  product:
    okrs:
      - objective: "Launch intelligent document processing"
        key_results:
          - id: "kr-p-1"
            description: "Deploy ML classification with 90% accuracy"
            metrics:
              - metric: "Classification accuracy"
                baseline: 0
                target: 90

    riskiest_assumptions:
      - id: "asm-p-001"
        assumption: "ML model can handle document variety"
        linked_to_kr: "kr-p-1"
        validation_approach: "Test with customer documents"
        current_confidence: "low"
```

### After (v2.8.0)

```yaml
# Roadmap Recipe - Product Track
# EPF v2.8.0

tracks:
  product:
    okrs:
      - objective: "Launch intelligent document processing"
        key_results:
          - id: "kr-p-1"
            description: "Deploy ML classification with 90% accuracy"
            metrics:
              - metric: "Classification accuracy"
                baseline: 0
                target: 90
            
            # TRL tracking for ML development maturity
            trl_start: 3
            trl_target: 7
            trl_progression:
              - level: 4
                target_date: "2025-02-28"
                milestone: "Model validated on synthetic dataset"
                evidence_required: ">85% accuracy on 500 test docs"
              - level: 5
                target_date: "2025-03-31"
                milestone: "Model validated on real customer documents"
                evidence_required: ">90% accuracy on customer sample"
              - level: 6
                target_date: "2025-04-30"
                milestone: "Prototype in staging environment"
                evidence_required: "Processing 100 docs/day reliably"
              - level: 7
                target_date: "2025-05-31"
                milestone: "Production deployment"
                evidence_required: "90% accuracy sustained for 2 weeks"
            
            technical_hypothesis: |
              We believe that a fine-tuned transformer model can 
              achieve 90% classification accuracy across our 15 
              document types, with inference latency under 2 seconds. 
              This would eliminate the need for manual document 
              sorting, saving ~20 hours/week of operations time.

    riskiest_assumptions:
      - id: "asm-p-001"
        assumption: "ML model can handle document variety"
        linked_to_kr: "kr-p-1"
        validation_approach: "Test with customer documents"
        current_confidence: "low"
        
        success_criteria:
          - "90% accuracy across all 15 document types"
          - "No single document type below 80% accuracy"
          - "Inference latency <2s for 95th percentile"
          - "Model size <500MB for edge deployment"
        
        uncertainty_addressed: |
          Our document corpus includes 15 distinct types with 
          significant variation in format, length, and structure. 
          We don't know if a single model can handle this variety 
          or if we need specialized models per document type. This 
          affects architecture decisions and development timeline.
        
        experiment_design: |
          Phase 1 (2 weeks): Collect 100 samples per document type
          Phase 2 (3 weeks): Train single unified model
          Phase 3 (1 week): Evaluate per-type accuracy
          
          Decision criteria:
          - If >90% overall AND no type <80%: Single model approach ✓
          - If 80-90% overall: Investigate ensemble approach
          - If <80% overall OR any type <70%: Pivot to specialized models
          
          Timeline impact: Specialized models add ~4 weeks to delivery
```

---

## ROI of This Migration

### Without TRL/Hypothesis Fields
- No visibility into technical maturity
- Assumptions validated ad-hoc
- Harder to make evidence-based pivot decisions
- Learning happens but isn't captured

### With TRL/Hypothesis Fields
- Clear innovation maturity tracking
- Structured validation approach
- Evidence-based pivot decisions
- Organizational learning preserved

**Recommended for**: Any roadmap with significant technical or market uncertainty.

---

## Post-Enrichment Validation

After adding TRL and hypothesis fields, run these checks:

### Required Checks (Must Pass)

```bash
# 1. Schema validation
./scripts/validate-schemas.sh _instances/{product}/READY/05_roadmap_recipe.yaml

# 2. Version alignment - should show CURRENT after updating version
./scripts/check-version-alignment.sh _instances/{product}/
```

### Content Quality Assessment

```bash
# Check field coverage improvement
./scripts/analyze-field-coverage.sh _instances/{product}/READY/05_roadmap_recipe.yaml

# Check content readiness
./scripts/check-content-readiness.sh _instances/{product}/READY/05_roadmap_recipe.yaml
```

**What to Expect:**

Since this is optional enrichment (not breaking change migration):

| Before Enrichment | After TRL Fields | After Both TRL + Hypothesis |
|-------------------|------------------|----------------------------|
| ~40% coverage | ~60% coverage | ~80% coverage |
| Grade C-D | Grade B-C | Grade A-B |

**Note**: These fields are optional. If you choose not to add them:
- Schema validation will still pass
- Content readiness will note "optional enrichment available"
- Your roadmap remains valid for current EPF version

### Understanding the Grades

- **Grade A (90-100)**: Full TRL + hypothesis coverage, production-ready
- **Grade B (75-89)**: TRL fields added, some hypothesis fields
- **Grade C (60-74)**: Basic roadmap, no TRL/hypothesis fields
- **Grade D (<60)**: Missing required fields or significant template content

---

## Support

If you encounter issues:

1. Validate against schema: `./scripts/validate-schemas.sh {file}`
2. Check field coverage: `./scripts/analyze-field-coverage.sh {file}`
3. Review TRL definitions in this guide
4. Consult [MIGRATIONS.md](../MIGRATIONS.md) for general guidance
