import {
  Injectable,
  BadRequestException,
  NotFoundException,
  Inject,
  Optional,
  Logger,
} from '@nestjs/common';
import { createHash } from 'crypto';
import {
  pairIndependentHeads,
  pairIndependentRelationshipHeads,
} from './merge.util';
import { DatabaseService } from '../../common/database/database.service';
import { diffProperties } from '../../graph/change-summary';
import { generateDiff, computeContentHash, isNoOpChange } from './diff.util';
import { TypeRegistryService } from '../type-registry/type-registry.service';
import { CreateGraphObjectDto } from './dto/create-graph-object.dto';
import { PatchGraphObjectDto } from './dto/patch-graph-object.dto';
import {
  GraphObjectDto,
  GraphObjectRow,
  GraphRelationshipDto,
  GraphRelationshipRow,
  GraphTraversalResult,
} from './graph.types';
import { TraverseGraphDto } from './dto/traverse-graph.dto';
import { CreateGraphRelationshipDto } from './dto/create-graph-relationship.dto';
import { SchemaRegistryService } from './schema-registry.service';
import { EmbeddingJobsService } from './embedding-jobs.service';
import { EmbeddingPolicyService } from './embedding-policy.service';
import { AppConfigService } from '../../common/config/config.service';
import { PatchGraphRelationshipDto } from './dto/patch-graph-relationship.dto';
import {
  BranchMergeRequestDto,
  BranchMergeSummaryDto,
  BranchMergeObjectStatus,
  BranchMergeObjectSummaryDto,
  BranchMergeRelationshipSummaryDto,
  BranchMergeRelationshipStatus,
} from './dto/merge.dto';
import { evaluatePredicates } from './predicate-evaluator';
import { buildTemporalFilterClause } from './temporal-filter.util';
import { pruneGraphResult, FieldStrategy } from './utils/field-pruning.util';
import { buildExpirationFilterClause } from './utils/expiration-filter.util';
import { GraphVectorSearchService } from './graph-vector-search.service';

type GraphTenantContext = {
  orgId?: string | null;
  projectId?: string | null;
};

@Injectable()
export class GraphService {
  private readonly logger = new Logger(GraphService.name);
  /**
   * Find a merge base (lowest common ancestor) between two object/relationship version IDs using
   * the kb.merge_provenance parent linkage graph. This performs a bounded bidirectional ancestry
   * expansion (depth-first via recursion) and returns the first common ancestor minimizing
   * combined depth (s_depth + t_depth). If none is found within the depth budget the function
   * returns null. The search intentionally treats provenance parents uniformly (roles source|target|base)
   * because for ancestry purposes any parent edge expresses historical precedence.
   *
   * Depth bound (MERGE_BASE_MAX_DEPTH env, default 20) keeps worst-case explosion in check.
   * This is an MVP heuristic; future iterations may incorporate explicit version timestamps or
   * topological ordering to break ties more deterministically.
   */
  private async findMergeBase(
    sourceVersionId: string,
    targetVersionId: string
  ): Promise<string | null> {
    if (
      !sourceVersionId ||
      !targetVersionId ||
      sourceVersionId === targetVersionId
    )
      return null;
    const maxDepth = parseInt(
      process.env.GRAPH_MERGE_BASE_MAX_DEPTH || '20',
      10
    );
    const sql = `WITH RECURSIVE src_anc(id, depth) AS (
                          SELECT $1::uuid, 0
                          UNION ALL
                          SELECT mp.parent_version_id, depth + 1
                          FROM kb.merge_provenance mp
                          JOIN src_anc sa ON mp.child_version_id = sa.id
                          WHERE sa.depth < $3
                      ),
                      tgt_anc(id, depth) AS (
                          SELECT $2::uuid, 0
                          UNION ALL
                          SELECT mp.parent_version_id, depth + 1
                          FROM kb.merge_provenance mp
                          JOIN tgt_anc ta ON mp.child_version_id = ta.id
                          WHERE ta.depth < $3
                      ),
                      common AS (
                          SELECT s.id, s.depth AS s_depth, t.depth AS t_depth, (s.depth + t.depth) AS total_depth
                          FROM src_anc s
                          JOIN tgt_anc t ON s.id = t.id
                      )
                      SELECT id FROM common ORDER BY total_depth, s_depth, t_depth LIMIT 1`;
    try {
      const res = await this.db.query<{ id: string }>(sql, [
        sourceVersionId,
        targetVersionId,
        maxDepth,
      ]);
      if (res.rowCount) return res.rows[0].id;
    } catch (e) {
      // Non-blocking; merge logic can proceed without a base. Swallow errors to avoid
      // failing the entire merge dry-run due to an LCA query issue.
    }
    return null;
  }
  constructor(
    @Inject(DatabaseService) private readonly db: DatabaseService,
    @Inject(SchemaRegistryService)
    private readonly schemaRegistry: SchemaRegistryService,
    @Optional()
    @Inject(TypeRegistryService)
    private readonly typeRegistry?: TypeRegistryService,
    @Optional()
    @Inject(EmbeddingJobsService)
    private readonly embeddingJobs?: EmbeddingJobsService,
    @Optional()
    @Inject(EmbeddingPolicyService)
    private readonly embeddingPolicy?: EmbeddingPolicyService,
    @Optional()
    @Inject(AppConfigService)
    private readonly config?: AppConfigService,
    @Optional()
    @Inject(GraphVectorSearchService)
    private readonly vectorSearch?: GraphVectorSearchService
  ) {}

  private sortObject(value: any): any {
    // stable key ordering for hashing
    if (value === null || typeof value !== 'object') return value;
    if (Array.isArray(value)) return value.map((v) => this.sortObject(v));
    const entries = Object.keys(value)
      .sort()
      .map((k) => [k, this.sortObject(value[k])]);
    return Object.fromEntries(entries);
  }

  private async withTenantContext<T>(
    orgId: string | null | undefined,
    projectId: string | null | undefined,
    fn: () => Promise<T>
  ): Promise<T> {
    const candidate = (this.db as any)?.runWithTenantContext;
    const normalizedOrg = orgId ?? null;
    const normalizedProject = projectId ?? null;
    if (typeof candidate === 'function') {
      return candidate.call(this.db, normalizedOrg, normalizedProject, fn);
    }

    const setContext = (this.db as any)?.setTenantContext;
    const getContext = (this.db as any)?.getCurrentTenantContext;
    let reset: (() => Promise<void>) | null = null;

    if (typeof setContext === 'function') {
      let previousOrg: string | null = null;
      let previousProject: string | null = null;
      if (typeof getContext === 'function') {
        try {
          const current = await getContext.call(this.db);
          previousOrg = current?.orgId ?? null;
          previousProject = current?.projectId ?? null;
        } catch {
          /* ignore */
        }
      }
      await setContext.call(this.db, normalizedOrg, normalizedProject);
      reset = async () => {
        await setContext.call(
          this.db,
          previousOrg ?? null,
          previousProject ?? null
        );
      };
    }

    try {
      return await fn();
    } finally {
      if (reset) {
        try {
          await reset();
        } catch {
          /* ignore */
        }
      }
    }
  }

  private getAmbientTenantContext(): {
    orgId: string | null | undefined;
    projectId: string | null | undefined;
  } {
    let org: string | null | undefined;
    let project: string | null | undefined;
    const storage = (this.db as any)?.tenantContextStorage;
    if (storage && typeof storage.getStore === 'function') {
      try {
        const store = storage.getStore();
        if (store) {
          org = store.orgId;
          project = store.projectId;
        }
      } catch {
        /* ignore */
      }
    }
    if (org === undefined) {
      try {
        org = (this.db as any)?.currentOrgId;
      } catch {
        /* ignore */
      }
    }
    if (project === undefined) {
      try {
        project = (this.db as any)?.currentProjectId;
      } catch {
        /* ignore */
      }
    }
    return { orgId: org, projectId: project };
  }

  private async runWithRequestContext<T>(
    ctx: GraphTenantContext | undefined,
    fallbackOrg: string | null | undefined,
    fallbackProject: string | null | undefined,
    fn: () => Promise<T>
  ): Promise<T> {
    const ambient = this.getAmbientTenantContext();
    const ctxHasOrg = ctx
      ? Object.prototype.hasOwnProperty.call(ctx, 'orgId')
      : false;
    const ctxHasProject = ctx
      ? Object.prototype.hasOwnProperty.call(ctx, 'projectId')
      : false;
    const orgSource = ctxHasOrg
      ? ctx!.orgId
      : fallbackOrg !== undefined
      ? fallbackOrg
      : ambient.orgId;
    const projectSource = ctxHasProject
      ? ctx!.projectId
      : fallbackProject !== undefined
      ? fallbackProject
      : ambient.projectId;
    if (process.env.DEBUG_TENANT === 'true') {
      // eslint-disable-next-line no-console
      console.log('[graph.runWithRequestContext]', {
        ctx,
        fallbackOrg,
        fallbackProject,
        ambient,
        orgSource,
        projectSource,
      });
    }
    const shouldApplyContext =
      orgSource !== undefined || projectSource !== undefined;
    if (!shouldApplyContext) {
      return fn();
    }
    const normalizedOrg = orgSource ?? null;
    const normalizedProject = projectSource ?? null;
    return this.withTenantContext(normalizedOrg, normalizedProject, fn);
  }

  async createObject(
    input: CreateGraphObjectDto & { branch_id?: string | null },
    ctx?: GraphTenantContext
  ): Promise<GraphObjectDto> {
    let {
      type,
      key,
      status,
      properties = {},
      labels = [],
      organization_id = null,
      org_id = null,
      project_id = null,
      branch_id = null,
    } = input as any;

    if (!org_id && organization_id) {
      org_id = organization_id;
    }

    const hasOrgField =
      Object.prototype.hasOwnProperty.call(input as any, 'org_id') ||
      Object.prototype.hasOwnProperty.call(input as any, 'organization_id');
    const hasProjectField = Object.prototype.hasOwnProperty.call(
      input as any,
      'project_id'
    );
    const contextOrg = hasOrgField ? org_id ?? null : undefined;
    const contextProject = hasProjectField ? project_id ?? null : undefined;

    return this.runWithRequestContext(
      ctx,
      contextOrg,
      contextProject,
      async () => {
        const client = await this.db.getClient();
        try {
          // Fallback: if caller did not supply org/project, derive from session GUCs (tenant context) on the same connection.
          if (!org_id) {
            try {
              const guc = await client.query<{ org: string | null }>(
                "SELECT current_setting('app.current_organization_id', true) as org"
              );
              org_id = guc.rows[0]?.org || null;
            } catch {
              /* ignore */
            }
          }
          if (!project_id) {
            try {
              const guc = await client.query<{ proj: string | null }>(
                "SELECT current_setting('app.current_project_id', true) as proj"
              );
              project_id = guc.rows[0]?.proj || null;
            } catch {
              /* ignore */
            }
          }

          // Branch existence validation (if provided)
          if (branch_id) {
            const branch = await client.query<{ id: string }>(
              `SELECT id FROM kb.branches WHERE id=$1`,
              [branch_id]
            );
            if (!branch.rowCount)
              throw new NotFoundException('branch_not_found');
          }

          // Schema validation (if schema exists for type)
          const validator = await this.schemaRegistry.getObjectValidator(
            project_id ?? null,
            type
          );
          if (validator) {
            const valid = validator(properties || {});
            if (!valid) {
              throw new BadRequestException({
                code: 'object_schema_validation_failed',
                errors: validator.errors,
              });
            }
          }

          // Type Registry validation (Phase 1 dynamic type system)
          if (this.typeRegistry && project_id && org_id) {
            try {
              const validationResult =
                await this.typeRegistry.validateObjectData(project_id, org_id, {
                  type,
                  properties: properties || {},
                });
              if (!validationResult.valid && validationResult.errors) {
                throw new BadRequestException({
                  code: 'type_registry_validation_failed',
                  message: 'Object properties do not match type schema',
                  errors: validationResult.errors,
                });
              }
            } catch (error) {
              // If type not found in registry, allow creation (type registry is optional)
              if (error instanceof NotFoundException) {
                // Type not registered yet - allow creation
              } else if (error instanceof BadRequestException) {
                // Type is disabled or validation failed - propagate error
                throw error;
              }
              // Other errors (e.g., DB connection) - log but don't block
            }
          }

          await client.query('BEGIN');
          if (key) {
            // Transaction-scoped advisory lock to serialize creation by logical identity
            await client.query(
              'SELECT pg_advisory_xact_lock(hashtext($1)::bigint)',
              [`obj|${project_id}|${type}|${key}`]
            );
            // Head = max(version) for (project_id,type,key)
            const existing = await client.query<GraphObjectRow>(
              `SELECT id, project_id, branch_id, canonical_id, supersedes_id, version, type, key, properties, labels, created_at
                         FROM kb.graph_objects
                         WHERE project_id IS NOT DISTINCT FROM $1 AND branch_id IS NOT DISTINCT FROM $2 AND type=$3 AND KEY=$4
                         ORDER BY version DESC
                         LIMIT 1`,
              [project_id, branch_id, type, key]
            );
            if (existing.rowCount) {
              throw new BadRequestException('object_key_exists');
            }
          }
          // Deduplicate labels (prevent duplicates on insert)
          const dedupedLabels = Array.from(new Set(labels));
          // Compute content hash using new utility (returns Buffer, convert to base64)
          const hashBuffer = computeContentHash(properties);
          const hash = hashBuffer.toString('base64');
          // Compute rich change summary (treat prior state as empty object). Empty previous state ensures all provided
          // properties register as added paths with proper meta counters and path union.
          const changeSummary = generateDiff({}, properties);
          // Inline FTS population (basic lexical vector) over type, key, and serialized properties.
          // IMPORTANT: Do NOT reuse the JSON properties parameter ($3) inside the FTS expression because
          // PostgreSQL will attempt to infer a single type for $3 across JSONB and text concatenation usages,
          // yielding "inconsistent types deduced" errors. Instead, we duplicate the serialized properties
          // string as a later parameter ($10) that is explicitly text.
          const ftsVectorSql = `to_tsvector('simple', coalesce($1,'') || ' ' || coalesce($2,'') || ' ' || coalesce($9,'') )`;
          const row = await client.query<GraphObjectRow>(
            `INSERT INTO kb.graph_objects(type, key, status, properties, labels, version, canonical_id, project_id, branch_id, change_summary, content_hash, fts, embedding, embedding_updated_at)
                     VALUES ($1,$2,$10,$3,$4,1,gen_random_uuid(),$5,$6,$7,$8, ${ftsVectorSql}, NULL, NULL)
                     RETURNING id, project_id, branch_id, canonical_id, supersedes_id, version, type, key, status, properties, labels, deleted_at, change_summary, content_hash, fts, created_at`,
            [
              type,
              key ?? null,
              properties,
              dedupedLabels,
              project_id,
              branch_id,
              changeSummary,
              hash,
              JSON.stringify(properties),
              status ?? null,
            ]
          );
          await client.query('COMMIT');
          const created = row.rows[0];

          // Policy-aware embedding job enqueueing (Phase 3: selective embedding)
          if (
            this.isEmbeddingsEnabled() &&
            (created as any).embedding == null
          ) {
            try {
              // Check policies before queueing
              if (this.embeddingPolicy && project_id) {
                const policies = await this.embeddingPolicy.findByProject(
                  project_id
                );
                const evaluation = this.embeddingPolicy.shouldEmbed(
                  created.type,
                  created.properties,
                  created.labels,
                  policies,
                  (created as any).status ?? null
                );

                if (evaluation.shouldEmbed) {
                  await this.embeddingJobs?.enqueue(created.id);
                }
              } else {
                // No policy service or project context: default to enqueueing (backward compatible)
                await this.embeddingJobs?.enqueue(created.id);
              }
            } catch {
              /* swallow embedding queue errors */
            }
          }

          return created;
        } catch (e) {
          try {
            await client.query('ROLLBACK');
          } catch {
            /* ignore */
          }
          throw e;
        } finally {
          client.release();
        }
      }
    );
  }

  async getObject(
    id: string,
    ctx?: GraphTenantContext
  ): Promise<GraphObjectDto> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const res = await this.db.query<
        GraphObjectRow & { revision_count: number }
      >(
        `SELECT 
                    o.id, o.project_id, o.canonical_id, o.supersedes_id, o.version, 
                    o.type, o.key, o.properties, o.labels, o.deleted_at, o.created_at,
                    o.embedding, o.embedding_updated_at,
                    COALESCE(rc.revision_count, 1) as revision_count
                 FROM kb.graph_objects o
                 LEFT JOIN kb.graph_object_revision_counts rc ON rc.canonical_id = o.canonical_id
                 WHERE o.id=$1`,
        [id]
      );
      if (!res.rowCount) throw new NotFoundException('object_not_found');
      return res.rows[0];
    });
  }

  /**
   * Get all distinct tags across all graph objects in the project.
   * Tags are stored in properties.tags as an array of strings.
   * This method is used for:
   * 1. Populating tag filter dropdowns in the UI
   * 2. Providing available tags to LLM extraction prompts
   *
   * @param ctx Tenant context (org_id, project_id)
   * @returns Array of distinct tag strings, sorted alphabetically
   */
  async getAllTags(ctx?: GraphTenantContext): Promise<string[]> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const res = await this.db.query<{ tag: string }>(
        `SELECT DISTINCT jsonb_array_elements_text(properties->'tags') as tag 
                 FROM kb.graph_objects 
                 WHERE properties ? 'tags'
                 AND properties->'tags' IS NOT NULL
                 AND deleted_at IS NULL
                 ORDER BY tag`
      );
      return res.rows.map((row: any) => row.tag);
    });
  }

  /**
   * Get version history for an object by its ID.
   * Returns all versions in the version chain (linked by canonical_id).
   * Versions are ordered newest to oldest (version DESC).
   *
   * @param objectId The ID of any version of the object
   * @param ctx Tenant context for RLS
   * @returns Array of all versions with metadata
   * @throws NotFoundException if object not found
   */
  async getObjectVersions(
    objectId: string,
    ctx?: GraphTenantContext
  ): Promise<any[]> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      // First, get the canonical_id for this object
      const objRes = await this.db.query<{
        canonical_id: string;
        version: number;
      }>(`SELECT canonical_id, version FROM kb.graph_objects WHERE id = $1`, [
        objectId,
      ]);

      if (objRes.rows.length === 0) {
        throw new NotFoundException(`Object with id ${objectId} not found`);
      }

      const { canonical_id, version: currentVersion } = objRes.rows[0];

      // Get all versions in this chain
      const versionsRes = await this.db.query<GraphObjectRow>(
        `SELECT 
                    id, version, supersedes_id, canonical_id,
                    type, key, properties, labels,
                    change_summary, content_hash,
                    created_at, deleted_at
                FROM kb.graph_objects
                WHERE canonical_id = $1
                ORDER BY version DESC`,
        [canonical_id]
      );

      // Map to version DTOs
      return versionsRes.rows.map((row: any, idx: any) => {
        // Extract user info from properties if available
        const createdBy = row.properties?._created_by as string | undefined;
        const extractionJobId = row.properties?._extraction_job_id as
          | string
          | undefined;

        return {
          id: row.id,
          version: row.version,
          supersedes_id: row.supersedes_id || undefined,
          canonical_id: row.canonical_id,
          type: row.type,
          key: row.key || undefined,
          properties: row.properties || {},
          labels: row.labels || [],
          change_summary: row.change_summary || undefined,
          content_hash: row.content_hash
            ? Buffer.from(row.content_hash).toString('base64')
            : undefined,
          created_at: row.created_at,
          deleted_at: row.deleted_at || undefined,
          created_by: createdBy,
          extraction_job_id: extractionJobId,
          is_current: idx === 0 && row.version === currentVersion, // First item with matching version is current
        };
      });
    });
  }

  /**
   * Resolve object HEAD on a branch with lazy fallback to ancestor branches.
   * Per spec Section 5.6.1: Uses recursive CTE to walk branch lineage,
   * picks earliest depth (closest branch) then highest version.
   *
   * @param canonical_id The canonical_id of the object
   * @param branch_id The branch to resolve from
   * @returns The head version of the object on the branch or nearest ancestor
   * @throws NotFoundException if object not found on branch or any ancestor
   */
  async resolveObjectOnBranch(
    canonical_id: string,
    branch_id: string
  ): Promise<GraphObjectDto> {
    const res = await this.db.query<GraphObjectRow>(
      `WITH RECURSIVE lineage AS (
                SELECT b.id, 0 AS depth FROM kb.branches b WHERE b.id = $1
                UNION ALL
                SELECT bl.ancestor_branch_id, l.depth + 1
                FROM lineage l
                JOIN kb.branch_lineage bl ON bl.branch_id = l.id
                WHERE bl.ancestor_branch_id IS NOT NULL
            )
            SELECT o.id, o.project_id, o.branch_id, o.canonical_id, o.supersedes_id, 
                   o.version, o.type, o.key, o.properties, o.labels, o.deleted_at, 
                   o.change_summary, o.content_hash, o.created_at
            FROM lineage l
            JOIN kb.graph_objects o ON o.branch_id = l.id AND o.canonical_id = $2
            WHERE o.deleted_at IS NULL
            ORDER BY l.depth ASC, o.version DESC
            LIMIT 1`,
      [branch_id, canonical_id]
    );
    if (!res.rowCount)
      throw new NotFoundException('object_not_found_on_branch');
    return res.rows[0];
  }

  async patchObject(
    id: string,
    patch: PatchGraphObjectDto & { branch_id?: string | null },
    ctx?: GraphTenantContext
  ): Promise<GraphObjectDto> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const client = await this.db.getClient();
      try {
        await client.query('BEGIN');
        const currentRes = await client.query<GraphObjectRow>(
          `SELECT * FROM kb.graph_objects WHERE id=$1`,
          [id]
        );
        if (!currentRes.rowCount)
          throw new NotFoundException('object_not_found');
        const current = currentRes.rows[0];
        // Serialize patches for this logical object (canonical id)
        await client.query(
          'SELECT pg_advisory_xact_lock(hashtext($1)::bigint)',
          [`obj|${current.canonical_id}`]
        );
        // Ensure this id is still the head (no newer version exists)
        const newer = await client.query<{ id: string }>(
          'SELECT id FROM kb.graph_objects WHERE canonical_id=$1 AND version > $2 AND branch_id IS NOT DISTINCT FROM $3 LIMIT 1',
          [
            current.canonical_id,
            current.version,
            (current as any).branch_id ?? null,
          ]
        );
        if (newer.rowCount)
          throw new BadRequestException('cannot_patch_non_head_version');
        const nextProps = patch.properties
          ? { ...current.properties, ...patch.properties }
          : current.properties;
        // Validate with potential updated properties
        const validator = await this.schemaRegistry.getObjectValidator(
          (current as any).project_id ?? null,
          current.type
        );
        if (validator) {
          const valid = validator(nextProps);
          if (!valid)
            throw new BadRequestException({
              code: 'object_schema_validation_failed',
              errors: validator.errors,
            });
        }

        // Type Registry validation (Phase 1 dynamic type system)
        if (
          this.typeRegistry &&
          (current as any).project_id &&
          (current as any).organization_id
        ) {
          try {
            const validationResult = await this.typeRegistry.validateObjectData(
              (current as any).project_id,
              (current as any).organization_id,
              { type: current.type, properties: nextProps }
            );
            if (!validationResult.valid && validationResult.errors) {
              throw new BadRequestException({
                code: 'type_registry_validation_failed',
                message: 'Updated properties do not match type schema',
                errors: validationResult.errors,
              });
            }
          } catch (error) {
            // If type not found in registry, allow update (type registry is optional)
            if (error instanceof NotFoundException) {
              // Type not registered yet - allow update
            } else if (error instanceof BadRequestException) {
              // Type is disabled or validation failed - propagate error
              throw error;
            }
            // Other errors (e.g., DB connection) - log but don't block
          }
        }
        let nextLabels = current.labels;
        if (patch.labels) {
          nextLabels = patch.replaceLabels
            ? patch.labels
            : Array.from(new Set([...current.labels, ...patch.labels]));
        } else if (patch.replaceLabels) {
          nextLabels = [];
        }
        const nextStatus =
          patch.status !== undefined ? patch.status : (current as any).status;
        const diff = generateDiff(current.properties, nextProps);
        const labelsChanged =
          JSON.stringify(current.labels) !== JSON.stringify(nextLabels);
        const statusChanged = (current as any).status !== nextStatus;
        if (isNoOpChange(diff) && !labelsChanged && !statusChanged)
          throw new BadRequestException('no_effective_change');
        // Compute content hash using new utility
        const hashBuffer = computeContentHash(nextProps);
        const hash = hashBuffer.toString('base64');
        // Mark current version as superseded by setting deleted_at to prevent unique constraint violations
        await client.query(
          `UPDATE kb.graph_objects SET deleted_at = now() WHERE id = $1 AND deleted_at IS NULL`,
          [current.id]
        );
        // IMPORTANT: Keep serialized properties text parameter separate from JSONB properties to avoid type inference conflicts.
        const ftsVectorSql = `to_tsvector('simple', coalesce($12,'') || ' ' || coalesce($13,'') || ' ' || coalesce($14,'') )`;
        const inserted = await client.query<GraphObjectRow>(
          `INSERT INTO kb.graph_objects(type, key, status, properties, labels, version, canonical_id, supersedes_id, project_id, branch_id, deleted_at, change_summary, content_hash, fts, embedding, embedding_updated_at)
                     VALUES ($1,$2,$15,$3,$4,$5,$6,$7,$8,$9,NULL,$10,$11, ${ftsVectorSql}, NULL, NULL)
                     RETURNING id, project_id, branch_id, canonical_id, supersedes_id, version, type, key, status, properties, labels, deleted_at, change_summary, content_hash, fts, created_at`,
          [
            current.type,
            current.key,
            nextProps,
            nextLabels,
            current.version + 1,
            current.canonical_id,
            current.id,
            (current as any).project_id ?? null,
            (current as any).branch_id ?? null,
            diff,
            hash,
            current.key ?? '',
            JSON.stringify(nextProps),
            current.type,
            nextStatus ?? null,
          ]
        );
        await client.query('COMMIT');
        const updated = { ...inserted.rows[0], diff } as any;
        if (this.isEmbeddingsEnabled() && updated.embedding == null) {
          try {
            await this.embeddingJobs?.enqueue(updated.id);
          } catch {
            /* ignore */
          }
        }
        return updated;
      } catch (e) {
        try {
          await client.query('ROLLBACK');
        } catch {
          /* ignore */
        }
        throw e;
      } finally {
        client.release();
      }
    });
  }

  async listHistory(
    id: string,
    limitParam = 20,
    cursor?: string,
    ctx?: GraphTenantContext
  ): Promise<{ items: GraphObjectDto[]; next_cursor?: string }> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const limit = Number(limitParam) || 20;
      // Resolve canonical id first
      const base = await this.db.query<{ canonical_id: string }>(
        `SELECT canonical_id FROM kb.graph_objects WHERE id=$1`,
        [id]
      );
      if (!base.rowCount) throw new NotFoundException('object_not_found');
      const canonicalId = base.rows[0].canonical_id;
      const params: any[] = [canonicalId];
      let cursorClause = '';
      if (cursor) {
        params.push(cursor);
        cursorClause = ' AND version < $2';
      }
      params.push(limit + 1);
      const res = await this.db.query<GraphObjectRow>(
        `SELECT id, project_id, canonical_id, supersedes_id, version, type, key, properties, labels, deleted_at, created_at
                 FROM kb.graph_objects WHERE canonical_id=$1${cursorClause}
           ORDER BY version DESC
           LIMIT $${params.length}`,
        params
      );
      let next_cursor: string | undefined;
      let rows = res.rows;
      // We fetched limit+1 to decide on a next cursor. Use the last returned item's version
      // (not the extra one) as cursor so predicate version < cursor fetches strictly older versions.
      if (rows.length > limit) {
        next_cursor = rows[limit - 1].version.toString();
        rows = rows.slice(0, limit);
      }
      return { items: rows, next_cursor };
    });
  }

  // ---------------- Relationships ----------------
  async createRelationship(
    input: CreateGraphRelationshipDto & { branch_id?: string | null },
    orgId: string,
    projectId: string
  ): Promise<GraphRelationshipDto> {
    const {
      type,
      src_id,
      dst_id,
      properties = {},
      branch_id = null,
    } = input as any;
    if (src_id === dst_id)
      throw new BadRequestException('self_loop_not_allowed');

    const contextOrg = orgId ?? null;
    const contextProject = projectId ?? null;

    return this.withTenantContext(contextOrg, contextProject, async () => {
      const client = await this.db.getClient();
      try {
        await client.query('BEGIN');
        // Validate endpoints exist & not deleted
        const objs = await client.query<{
          id: string;
          project_id: string | null;
          deleted_at: string | null;
          branch_id: string | null;
        }>(
          `SELECT id, project_id, deleted_at, branch_id FROM kb.graph_objects WHERE id = ANY($1::uuid[])`,
          [[src_id, dst_id]]
        );
        if (objs.rowCount !== 2) {
          const missingSrc = !objs.rows.find((r) => r.id === src_id);
          const missingDst = !objs.rows.find((r) => r.id === dst_id);
          if (missingSrc) throw new NotFoundException('src_object_not_found');
          if (missingDst) throw new NotFoundException('dst_object_not_found');
        }
        const srcObj = objs.rows.find((r) => r.id === src_id)!;
        const dstObj = objs.rows.find((r) => r.id === dst_id)!;
        if (srcObj.deleted_at)
          throw new BadRequestException('src_object_deleted');
        if (dstObj.deleted_at)
          throw new BadRequestException('dst_object_deleted');
        // Enforce same project
        if (
          (srcObj.project_id ?? null) !== (projectId ?? null) ||
          (dstObj.project_id ?? null) !== (projectId ?? null)
        ) {
          throw new BadRequestException('relationship_project_mismatch');
        }
        // Branch existence & consistency
        if (branch_id) {
          const b = await client.query<{ id: string }>(
            `SELECT id FROM kb.branches WHERE id=$1`,
            [branch_id]
          );
          if (!b.rowCount) throw new NotFoundException('branch_not_found');
          if (
            (srcObj.branch_id ?? null) !== (branch_id ?? null) ||
            (dstObj.branch_id ?? null) !== (branch_id ?? null)
          ) {
            throw new BadRequestException('relationship_branch_mismatch');
          }
        } else {
          // If no branch specified, require both endpoints in same (null) branch or identical branch id
          if ((srcObj.branch_id ?? null) !== (dstObj.branch_id ?? null)) {
            throw new BadRequestException('relationship_branch_mismatch');
          }
        }
        const effectiveBranchId =
          branch_id !== undefined && branch_id !== null
            ? branch_id
            : srcObj.branch_id ?? null;
        // Fetch multiplicity (default many-many) and enforce BEFORE identity lock to surface side-specific errors early.
        const multiplicity =
          await this.schemaRegistry.getRelationshipMultiplicity(
            projectId,
            type
          );
        // For 'one' sides we serialize creation across all relationships sharing that endpoint & type to avoid race duplicates.
        if (multiplicity.src === 'one') {
          await client.query(
            'SELECT pg_advisory_xact_lock(hashtext($1)::bigint)',
            [`rel|src|${projectId}|${type}|${src_id}`]
          );
          const existingSrc = await client.query<{ id: string }>(
            `SELECT id FROM kb.graph_relationships
                     WHERE project_id=$1 AND type=$2 AND src_id=$3 AND supersedes_id IS NULL AND deleted_at IS NULL
                     LIMIT 1`,
            [projectId, type, src_id]
          );
          if (existingSrc.rowCount) {
            await client.query('ROLLBACK');
            throw new BadRequestException({
              code: 'relationship_multiplicity_violation',
              side: 'src',
              type,
            });
          }
        }
        if (multiplicity.dst === 'one') {
          await client.query(
            'SELECT pg_advisory_xact_lock(hashtext($1)::bigint)',
            [`rel|dst|${projectId}|${type}|${dst_id}`]
          );
          const existingDst = await client.query<{ id: string }>(
            `SELECT id FROM kb.graph_relationships
                     WHERE project_id=$1 AND type=$2 AND dst_id=$3 AND supersedes_id IS NULL AND deleted_at IS NULL
                     LIMIT 1`,
            [projectId, type, dst_id]
          );
          if (existingDst.rowCount) {
            await client.query('ROLLBACK');
            throw new BadRequestException({
              code: 'relationship_multiplicity_violation',
              side: 'dst',
              type,
            });
          }
        }
        // Serialize relationship creation/upsert on logical identity
        await client.query(
          'SELECT pg_advisory_xact_lock(hashtext($1)::bigint)',
          [`rel|${projectId}|${type}|${src_id}|${dst_id}`]
        );
        const head = await client.query<GraphRelationshipRow>(
          `SELECT * FROM kb.graph_relationships
                 WHERE project_id=$1 AND branch_id IS NOT DISTINCT FROM $2 AND type=$3 AND src_id=$4 AND dst_id=$5
                 ORDER BY version DESC LIMIT 1`,
          [projectId, effectiveBranchId, type, src_id, dst_id]
        );
        if (!head.rowCount) {
          // Validate relationship properties if schema exists
          const validator = await this.schemaRegistry.getRelationshipValidator(
            projectId,
            type
          );
          if (validator) {
            const valid = validator(properties || {});
            if (!valid)
              throw new BadRequestException({
                code: 'relationship_schema_validation_failed',
                errors: validator.errors,
              });
          }
          const stable = JSON.stringify(this.sortObject(properties));
          const hash = createHash('sha256').update(stable).digest('base64');
          const changeSummary = diffProperties({}, properties) || null;
          const inserted = await client.query<GraphRelationshipRow>(
            `INSERT INTO kb.graph_relationships(project_id, branch_id, type, src_id, dst_id, properties, version, canonical_id, change_summary, content_hash)
                     VALUES ($1,$2,$3,$4,$5,$6,1,gen_random_uuid(),$7,$8)
                     RETURNING id, project_id, branch_id, type, src_id, dst_id, properties, version, supersedes_id, canonical_id, change_summary, content_hash, deleted_at, created_at`,
            [
              projectId,
              effectiveBranchId,
              type,
              src_id,
              dst_id,
              properties,
              changeSummary,
              hash,
            ]
          );
          await client.query('COMMIT');
          return inserted.rows[0];
        }
        const current = head.rows[0];
        const diff = diffProperties(current.properties, properties);
        if (!diff) {
          await client.query('ROLLBACK');
          return current; // no-op
        }
        const nextVersion = (current.version || 1) + 1;
        // Validate updated relationship properties if schema exists
        const validator = await this.schemaRegistry.getRelationshipValidator(
          current.project_id,
          current.type
        );
        if (validator) {
          const valid = validator(properties || {});
          if (!valid)
            throw new BadRequestException({
              code: 'relationship_schema_validation_failed',
              errors: validator.errors,
            });
        }
        const stable = JSON.stringify(this.sortObject(properties));
        const hash = createHash('sha256').update(stable).digest('base64');
        const inserted = await client.query<GraphRelationshipRow>(
          `INSERT INTO kb.graph_relationships(project_id, branch_id, type, src_id, dst_id, properties, version, canonical_id, supersedes_id, change_summary, content_hash)
                 VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11)
                 RETURNING id, project_id, branch_id, type, src_id, dst_id, properties, version, supersedes_id, canonical_id, change_summary, content_hash, deleted_at, created_at`,
          [
            projectId,
            (current as any).branch_id ?? null,
            type,
            src_id,
            dst_id,
            properties,
            nextVersion,
            current.canonical_id,
            current.id,
            diff,
            hash,
          ]
        );
        await client.query('COMMIT');
        return { ...inserted.rows[0], diff };
      } catch (e) {
        try {
          await client.query('ROLLBACK');
        } catch {
          /* ignore */
        }
        throw e;
      } finally {
        client.release();
      }
    });
  }

  async getRelationship(
    id: string,
    ctx?: GraphTenantContext
  ): Promise<GraphRelationshipDto> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const res = await this.db.query<GraphRelationshipRow>(
        `SELECT id, project_id, branch_id, type, src_id, dst_id, properties, version, supersedes_id, canonical_id, deleted_at, created_at, change_summary, content_hash
                 FROM kb.graph_relationships WHERE id=$1 AND deleted_at IS NULL`,
        [id]
      );
      if (!res.rowCount) throw new NotFoundException('relationship_not_found');
      return res.rows[0];
    });
  }

  async patchRelationship(
    id: string,
    patch: PatchGraphRelationshipDto,
    ctx?: GraphTenantContext
  ): Promise<GraphRelationshipDto> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const client = await this.db.getClient();
      try {
        await client.query('BEGIN');
        const currentRes = await client.query<GraphRelationshipRow>(
          `SELECT * FROM kb.graph_relationships WHERE id=$1 AND deleted_at IS NULL`,
          [id]
        );
        if (!currentRes.rowCount)
          throw new NotFoundException('relationship_not_found');
        const current = currentRes.rows[0];
        await client.query(
          'SELECT pg_advisory_xact_lock(hashtext($1)::bigint)',
          [
            `rel|${current.project_id}|${current.type}|${current.src_id}|${current.dst_id}`,
          ]
        );
        // Ensure current is still head
        const newer = await client.query<{ id: string }>(
          'SELECT id FROM kb.graph_relationships WHERE canonical_id=$1 AND version > $2 LIMIT 1',
          [current.canonical_id, current.version]
        );
        if (newer.rowCount)
          throw new BadRequestException('cannot_patch_non_head_version');
        const nextProps = patch.properties
          ? { ...current.properties, ...patch.properties }
          : current.properties;
        const diff = diffProperties(current.properties, nextProps);
        if (!diff) throw new BadRequestException('no_effective_change');
        const nextVersion = (current.version || 1) + 1;
        const stable = JSON.stringify(this.sortObject(nextProps));
        const hash = createHash('sha256').update(stable).digest('base64');
        const inserted = await client.query<GraphRelationshipRow>(
          `INSERT INTO kb.graph_relationships(project_id, branch_id, type, src_id, dst_id, properties, version, canonical_id, supersedes_id, deleted_at, change_summary, content_hash)
                     VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,NULL,$10,$11)
                     RETURNING id, project_id, branch_id, type, src_id, dst_id, properties, version, supersedes_id, canonical_id, deleted_at, change_summary, content_hash, created_at`,
          [
            current.project_id,
            (current as any).branch_id ?? null,
            current.type,
            current.src_id,
            current.dst_id,
            nextProps,
            nextVersion,
            current.canonical_id,
            current.id,
            diff,
            hash,
          ]
        );
        await client.query('COMMIT');
        return { ...inserted.rows[0], diff };
      } catch (e) {
        try {
          await client.query('ROLLBACK');
        } catch {
          /* ignore */
        }
        throw e;
      } finally {
        client.release();
      }
    });
  }

  async deleteObject(
    id: string,
    ctx?: GraphTenantContext
  ): Promise<GraphObjectDto> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const client = await this.db.getClient();
      try {
        await client.query('BEGIN');
        const currentRes = await client.query<GraphObjectRow>(
          `SELECT * FROM kb.graph_objects WHERE id=$1`,
          [id]
        );
        if (!currentRes.rowCount)
          throw new NotFoundException('object_not_found');
        const current = currentRes.rows[0];
        await client.query(
          'SELECT pg_advisory_xact_lock(hashtext($1)::bigint)',
          [`obj|${current.canonical_id}`]
        );
        const head = await client.query<GraphObjectRow>(
          `SELECT * FROM kb.graph_objects WHERE canonical_id=$1 ORDER BY version DESC LIMIT 1`,
          [current.canonical_id]
        );
        if (!head.rowCount) throw new NotFoundException('object_not_found');
        if (head.rows[0].deleted_at)
          throw new BadRequestException('already_deleted');
        const ftsVectorSql = `to_tsvector('simple', coalesce($10,'') || ' ' || coalesce($11,'') || ' ' || coalesce($12,'') )`;
        const tombstone = await client.query<GraphObjectRow>(
          `INSERT INTO kb.graph_objects(type, key, properties, labels, version, canonical_id, supersedes_id, project_id, deleted_at, fts, embedding, embedding_updated_at)
                     VALUES ($1,$2,$3,$4,$5,$6,$7,$8,now(), ${ftsVectorSql}, NULL, NULL)
                     RETURNING id, project_id, canonical_id, supersedes_id, version, type, key, properties, labels, deleted_at, fts, created_at`,
          [
            head.rows[0].type,
            head.rows[0].key,
            head.rows[0].properties,
            head.rows[0].labels,
            head.rows[0].version + 1,
            head.rows[0].canonical_id,
            head.rows[0].id,
            (head.rows[0] as any).project_id ?? null,
            head.rows[0].key ?? '',
            JSON.stringify(head.rows[0].properties),
            head.rows[0].type,
          ]
        );
        await client.query('COMMIT');
        return tombstone.rows[0];
      } catch (e) {
        try {
          await client.query('ROLLBACK');
        } catch {
          /* ignore */
        }
        throw e;
      } finally {
        client.release();
      }
    });
  }

  async restoreObject(
    id: string,
    ctx?: GraphTenantContext
  ): Promise<GraphObjectDto> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const client = await this.db.getClient();
      try {
        await client.query('BEGIN');
        // id may be tombstone or any historical version; resolve canonical
        const base = await client.query<GraphObjectRow>(
          `SELECT * FROM kb.graph_objects WHERE id=$1`,
          [id]
        );
        if (!base.rowCount) throw new NotFoundException('object_not_found');
        const canonicalId = base.rows[0].canonical_id;
        await client.query(
          'SELECT pg_advisory_xact_lock(hashtext($1)::bigint)',
          [`obj|${canonicalId}`]
        );
        const head = await client.query<GraphObjectRow>(
          `SELECT * FROM kb.graph_objects WHERE canonical_id=$1 ORDER BY version DESC LIMIT 1`,
          [canonicalId]
        );
        if (!head.rowCount) throw new NotFoundException('object_not_found');
        if (!head.rows[0].deleted_at)
          throw new BadRequestException('not_deleted');
        const prevLive = await client.query<GraphObjectRow>(
          `SELECT * FROM kb.graph_objects WHERE canonical_id=$1 AND deleted_at IS NULL ORDER BY version DESC LIMIT 1`,
          [canonicalId]
        );
        if (!prevLive.rowCount)
          throw new BadRequestException('no_prior_live_version');
        // Mark previous live version as superseded to prevent unique constraint violations
        await client.query(
          `UPDATE kb.graph_objects SET deleted_at = now() WHERE id = $1 AND deleted_at IS NULL`,
          [prevLive.rows[0].id]
        );
        // The restored version becomes the new HEAD (supersedes_id IS NULL)
        // FTS parameters use positions at end of array (after branch_id)
        const ftsVectorSql = `to_tsvector('simple', coalesce($10,'') || ' ' || coalesce($11,'') || ' ' || coalesce($12,'') )`;
        const restored = await client.query<GraphObjectRow>(
          `INSERT INTO kb.graph_objects(type, key, properties, labels, version, canonical_id, project_id, branch_id, deleted_at, fts, embedding, embedding_updated_at)
                     VALUES ($1,$2,$3,$4,$5,$6,$7,$8,NULL, ${ftsVectorSql}, NULL, NULL)
                     RETURNING id, project_id, branch_id, canonical_id, supersedes_id, version, type, key, properties, labels, deleted_at, fts, created_at`,
          [
            prevLive.rows[0].type,
            prevLive.rows[0].key,
            prevLive.rows[0].properties,
            prevLive.rows[0].labels,
            head.rows[0].version + 1,
            canonicalId,
            (prevLive.rows[0] as any).project_id ?? null,
            (prevLive.rows[0] as any).branch_id ?? null,
            prevLive.rows[0].key ?? '',
            JSON.stringify(prevLive.rows[0].properties),
            prevLive.rows[0].type,
          ]
        );
        await client.query('COMMIT');
        return restored.rows[0];
      } catch (e) {
        try {
          await client.query('ROLLBACK');
        } catch {
          /* ignore */
        }
        throw e;
      } finally {
        client.release();
      }
    });
  }

  async deleteRelationship(
    id: string,
    ctx?: GraphTenantContext
  ): Promise<GraphRelationshipDto> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const client = await this.db.getClient();
      try {
        await client.query('BEGIN');
        const currentRes = await client.query<GraphRelationshipRow>(
          `SELECT * FROM kb.graph_relationships WHERE id=$1`,
          [id]
        );
        if (!currentRes.rowCount)
          throw new NotFoundException('relationship_not_found');
        const current = currentRes.rows[0];
        await client.query(
          'SELECT pg_advisory_xact_lock(hashtext($1)::bigint)',
          [
            `rel|${current.project_id}|${current.type}|${current.src_id}|${current.dst_id}`,
          ]
        );
        const headRes = await client.query<GraphRelationshipRow>(
          `SELECT * FROM kb.graph_relationships WHERE canonical_id=$1 ORDER BY version DESC LIMIT 1`,
          [current.canonical_id]
        );
        if (!headRes.rowCount)
          throw new NotFoundException('relationship_not_found');
        const head = headRes.rows[0];
        if ((head as any).deleted_at)
          throw new BadRequestException('already_deleted');
        const tombstone = await client.query<GraphRelationshipRow>(
          `INSERT INTO kb.graph_relationships(project_id, branch_id, type, src_id, dst_id, properties, version, canonical_id, supersedes_id, deleted_at)
                     VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,now())
                     RETURNING id, project_id, branch_id, type, src_id, dst_id, properties, version, supersedes_id, canonical_id, deleted_at, created_at`,
          [
            head.project_id,
            (head as any).branch_id ?? null,
            head.type,
            head.src_id,
            head.dst_id,
            head.properties,
            (head.version || 1) + 1,
            head.canonical_id,
            head.id,
          ]
        );
        await client.query('COMMIT');
        return tombstone.rows[0];
      } catch (e) {
        try {
          await client.query('ROLLBACK');
        } catch {
          /* ignore */
        }
        throw e;
      } finally {
        client.release();
      }
    });
  }

  async restoreRelationship(
    id: string,
    ctx?: GraphTenantContext
  ): Promise<GraphRelationshipDto> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const client = await this.db.getClient();
      try {
        await client.query('BEGIN');
        const base = await client.query<GraphRelationshipRow>(
          `SELECT * FROM kb.graph_relationships WHERE id=$1`,
          [id]
        );
        if (!base.rowCount)
          throw new NotFoundException('relationship_not_found');
        const canonicalId = base.rows[0].canonical_id;
        await client.query(
          'SELECT pg_advisory_xact_lock(hashtext($1)::bigint)',
          [
            `rel|${base.rows[0].project_id}|${base.rows[0].type}|${base.rows[0].src_id}|${base.rows[0].dst_id}`,
          ]
        );
        const headRes = await client.query<GraphRelationshipRow>(
          `SELECT * FROM kb.graph_relationships WHERE canonical_id=$1 ORDER BY version DESC LIMIT 1`,
          [canonicalId]
        );
        if (!headRes.rowCount)
          throw new NotFoundException('relationship_not_found');
        const head = headRes.rows[0];
        if (!(head as any).deleted_at)
          throw new BadRequestException('not_deleted');
        const prevLive = await client.query<GraphRelationshipRow>(
          `SELECT * FROM kb.graph_relationships WHERE canonical_id=$1 AND deleted_at IS NULL ORDER BY version DESC LIMIT 1`,
          [canonicalId]
        );
        if (!prevLive.rowCount)
          throw new BadRequestException('no_prior_live_version');
        const prev = prevLive.rows[0];
        const restored = await client.query<GraphRelationshipRow>(
          `INSERT INTO kb.graph_relationships(project_id, branch_id, type, src_id, dst_id, properties, version, canonical_id, supersedes_id, deleted_at)
                     VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,NULL)
                     RETURNING id, project_id, branch_id, type, src_id, dst_id, properties, version, supersedes_id, canonical_id, deleted_at, created_at`,
          [
            prev.project_id,
            (prev as any).branch_id ?? null,
            prev.type,
            prev.src_id,
            prev.dst_id,
            prev.properties,
            (head.version || 1) + 1,
            canonicalId,
            head.id,
          ]
        );
        await client.query('COMMIT');
        return restored.rows[0];
      } catch (e) {
        try {
          await client.query('ROLLBACK');
        } catch {
          /* ignore */
        }
        throw e;
      } finally {
        client.release();
      }
    });
  }

  async listEdges(
    objectId: string,
    direction: 'out' | 'in' | 'both',
    limit = 50,
    ctx?: GraphTenantContext
  ): Promise<GraphRelationshipDto[]> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const dirClause =
        direction === 'out'
          ? 'r.src_id = $1'
          : direction === 'in'
          ? 'r.dst_id = $1'
          : '(r.src_id = $1 OR r.dst_id = $1)';
      // DISTINCT ON canonical_id to pick head (highest version)
      // IMPORTANT (graph-versioning): Select head (may be tombstone) first, THEN filter deleted heads outside.
      // Never push `deleted_at IS NULL` into the inner DISTINCT ON query or stale versions can resurface.
      // Previous implementation filtered deleted_at within the inner selection which could resurface a prior
      // non-deleted version after a tombstone delete. We now select the head (which may be deleted) then
      // filter out deleted heads in an outer query so a deleted relationship is fully hidden.
      const sql = `SELECT * FROM (
                     SELECT DISTINCT ON (r.canonical_id) r.id, r.project_id, r.type, r.src_id, r.dst_id, r.properties, r.version, r.supersedes_id, r.canonical_id, r.deleted_at, r.created_at, r.branch_id, r.change_summary, r.content_hash
                     FROM kb.graph_relationships r
                     WHERE ${dirClause}
                     ORDER BY r.canonical_id, r.version DESC
                 ) h
                 WHERE h.deleted_at IS NULL
                 LIMIT $2`;
      const res = await this.db.query<GraphRelationshipRow>(sql, [
        objectId,
        limit,
      ]);
      return res.rows;
    });
  }

  // ---------------- Search (basic filtering + forward cursor by created_at) ----------------
  async searchObjects(
    opts: {
      type?: string;
      key?: string;
      label?: string;
      limit?: number;
      cursor?: string;
      branch_id?: string | null;
      order?: 'asc' | 'desc';
      organization_id?: string;
      project_id?: string;
    },
    ctx?: GraphTenantContext
  ): Promise<{ items: GraphObjectDto[]; next_cursor?: string }> {
    const orgFilterProvided = Object.prototype.hasOwnProperty.call(
      opts,
      'organization_id'
    );
    const projectFilterProvided = Object.prototype.hasOwnProperty.call(
      opts,
      'project_id'
    );
    const fallbackOrg = orgFilterProvided
      ? opts.organization_id ?? null
      : undefined;
    const fallbackProject = projectFilterProvided
      ? opts.project_id ?? null
      : undefined;
    return this.runWithRequestContext(
      ctx,
      fallbackOrg,
      fallbackProject,
      async () => {
        const {
          type,
          key,
          label,
          limit = 20,
          cursor,
          branch_id,
          order = 'asc',
          organization_id,
          project_id,
        } = opts;
        // Head selection (may include deleted heads) followed by outer filter to exclude tombstones to avoid
        // resurfacing stale pre-delete versions.
        // Pattern reference: see docs/graph-versioning.md (head-first then filter).
        const headFilters: string[] = [];
        const headParams: any[] = [];
        if (branch_id !== undefined) {
          headParams.push(branch_id ?? null);
          headFilters.push(
            `branch_id IS NOT DISTINCT FROM $${headParams.length}`
          );
        }
        const headWhere = headFilters.length
          ? 'WHERE ' + headFilters.join(' AND ')
          : '';
        const baseHeadCte = `SELECT DISTINCT ON (canonical_id) id, project_id, branch_id, canonical_id, supersedes_id, version, type, key, status, properties, labels, deleted_at, created_at, embedding, embedding_updated_at
                                 FROM kb.graph_objects
                                 ${headWhere}
                                 ORDER BY canonical_id, version DESC`;
        const outerFilters: string[] = ['t.deleted_at IS NULL'];
        const outerParams: any[] = [...headParams];
        if (organization_id) {
          outerParams.push(organization_id);
          outerFilters.push(`t.organization_id = $${outerParams.length}`);
        }
        if (project_id) {
          outerParams.push(project_id);
          outerFilters.push(`t.project_id = $${outerParams.length}`);
        }
        if (type) {
          outerParams.push(type);
          outerFilters.push(`t.type = $${outerParams.length}`);
        }
        if (key) {
          outerParams.push(key);
          outerFilters.push(`t.key = $${outerParams.length}`);
        }
        if (label) {
          outerParams.push(label);
          outerFilters.push(`$${outerParams.length} = ANY(t.labels)`);
        }
        if (cursor) {
          outerParams.push(new Date(cursor));
          if (order === 'desc') {
            // Fetch older items when paging forward in a newest-first initial listing
            outerFilters.push(`t.created_at < $${outerParams.length}`);
          } else {
            // Ascending ordering: fetch newer items beyond cursor
            outerFilters.push(`t.created_at > $${outerParams.length}`);
          }
        }
        outerParams.push(limit + 1); // final param for limit
        const orderDir = order === 'desc' ? 'DESC' : 'ASC';
        const sql = `SELECT * FROM (${baseHeadCte}) t
                 WHERE ${outerFilters.join(' AND ')}
                 ORDER BY t.created_at ${orderDir}
                 LIMIT $${outerParams.length}`;
        const res = await this.db.query<GraphObjectRow>(sql, outerParams);
        let next_cursor: string | undefined;
        let rows = res.rows;
        if (rows.length > limit) {
          rows = rows.slice(0, limit);
        }
        if (rows.length) {
          // Cursor always reflects the created_at of the last row in the returned ordering.
          next_cursor = new Date(
            rows[rows.length - 1].created_at as any
          ).toISOString();
        }
        return { items: rows, next_cursor };
      }
    );
  }

  // ---------------- FTS Search (websearch syntax over inline populated tsvector) ----------------
  async searchObjectsFts(
    opts: {
      q: string;
      limit?: number;
      type?: string;
      label?: string;
      branch_id?: string | null;
      organization_id?: string;
      project_id?: string;
    },
    ctx?: GraphTenantContext
  ): Promise<{
    query: string;
    items: (GraphObjectDto & { rank: number })[];
    total: number;
    limit: number;
  }> {
    const orgFilterProvided = Object.prototype.hasOwnProperty.call(
      opts,
      'organization_id'
    );
    const projectFilterProvided = Object.prototype.hasOwnProperty.call(
      opts,
      'project_id'
    );
    const fallbackOrg = orgFilterProvided
      ? opts.organization_id ?? null
      : undefined;
    const fallbackProject = projectFilterProvided
      ? opts.project_id ?? null
      : undefined;
    return this.runWithRequestContext(
      ctx,
      fallbackOrg,
      fallbackProject,
      async () => {
        const q = (opts.q || '').trim();
        const limit = Math.min(Math.max(opts.limit || 20, 1), 100);
        if (!q) return { query: q, items: [], total: 0, limit };
        const params: any[] = [q];
        let idx = params.length;
        const filters: string[] = [];
        if (opts.organization_id) {
          params.push(opts.organization_id);
          idx++;
          filters.push(`h.organization_id = $${idx}`);
        }
        if (opts.project_id) {
          params.push(opts.project_id);
          idx++;
          filters.push(`h.project_id = $${idx}`);
        }
        if (opts.type) {
          params.push(opts.type);
          idx++;
          filters.push(`h.type = $${idx}`);
        }
        if (opts.label) {
          params.push(opts.label);
          idx++;
          filters.push(`$${idx} = ANY(h.labels)`);
        }
        if (opts.branch_id !== undefined) {
          params.push(opts.branch_id ?? null);
          idx++;
          filters.push(`h.branch_id IS NOT DISTINCT FROM $${idx}`);
        }
        // Head selection restricted to FTS matches first, then filter deleted heads; rank computed on head row's fts vector.
        const expirationClause = buildExpirationFilterClause('h');
        const buildSql = (
          expirationFilter: string,
          includeExpirationColumn: boolean
        ) => {
          const columnList = `o.id, o.project_id, o.branch_id, o.canonical_id, o.supersedes_id, o.version, o.type, o.key, o.status, o.properties, o.labels, o.deleted_at, o.created_at, o.fts, o.embedding, o.embedding_updated_at${
            includeExpirationColumn ? ', o.expires_at' : ''
          }`;
          return `WITH heads AS (
              SELECT DISTINCT ON (o.canonical_id) ${columnList}
              FROM kb.graph_objects o
              WHERE o.fts @@ websearch_to_tsquery('simple', $1)
              ORDER BY o.canonical_id, o.version DESC
          )
          SELECT *, ts_rank(fts, websearch_to_tsquery('simple', $1)) AS rank
          FROM heads h
          WHERE h.deleted_at IS NULL AND ${expirationFilter} ${
            filters.length ? 'AND ' + filters.join(' AND ') : ''
          }
          ORDER BY rank DESC, created_at DESC
          LIMIT ${limit}`;
        };
        let res;
        try {
          res = await this.db.query<any>(
            buildSql(expirationClause, true),
            params
          );
        } catch (error: any) {
          if (
            error?.code === '42703' &&
            typeof error?.message === 'string' &&
            error.message.includes('expires_at')
          ) {
            // Backward compatibility: older minimal schemas may lack expires_at. Retry without expiration filter.
            res = await this.db.query<any>(buildSql('TRUE', false), params);
          } else {
            throw error;
          }
        }
        const items = res.rows.map((r: any) => {
          const { rank, fts: _fts, ...rest } = r; // strip internal vector
          return { ...rest, rank } as GraphObjectDto & { rank: number };
        });
        return { query: q, items, total: items.length, limit };
      }
    );
  }

  /**
   * Search for objects using vector similarity and optionally include their neighbors.
   *
   * This method combines:
   * 1. Vector search (semantic similarity) - finds objects similar to query text
   * 2. Neighbor retrieval - for each result, finds:
   *    a) Semantically similar objects (via searchSimilar)
   *    b) Directly connected objects (via relationships)
   *
   * Similar to document search with citations, but for graph objects.
   *
   * @param queryText - Natural language query to search for
   * @param opts - Search options
   * @returns Primary search results + their neighbors (if requested)
   */
  async searchObjectsWithNeighbors(
    queryText: string,
    opts: {
      limit?: number;
      includeNeighbors?: boolean;
      maxNeighbors?: number;
      maxDistance?: number;
      projectId?: string;
      orgId?: string;
      branchId?: string | null;
      types?: string[];
      labels?: string[];
    },
    ctx?: GraphTenantContext
  ): Promise<{
    primaryResults: GraphObjectDto[];
    neighbors: Record<string, GraphObjectDto[]>;
  }> {
    const orgFilterProvided = Object.prototype.hasOwnProperty.call(
      opts,
      'orgId'
    );
    const projectFilterProvided = Object.prototype.hasOwnProperty.call(
      opts,
      'projectId'
    );
    const fallbackOrg = orgFilterProvided ? opts.orgId ?? null : undefined;
    const fallbackProject = projectFilterProvided
      ? opts.projectId ?? null
      : undefined;

    return this.runWithRequestContext(
      ctx,
      fallbackOrg,
      fallbackProject,
      async () => {
        const limit = Math.min(Math.max(opts.limit || 10, 1), 100);
        const maxNeighbors = Math.min(Math.max(opts.maxNeighbors || 5, 1), 20);

        if (!queryText?.trim()) {
          return { primaryResults: [], neighbors: {} };
        }

        if (!this.vectorSearch) {
          this.logger.warn(
            'GraphVectorSearchService not available, returning empty results'
          );
          return { primaryResults: [], neighbors: {} };
        }

        // Step 1: Generate embedding for query text
        // Note: This assumes embeddings are generated by EmbeddingJobsService
        // For now, we'll use searchObjectsFts as a fallback if vector search fails
        let primaryResults: GraphObjectDto[] = [];

        try {
          // Try FTS search first (since we don't have embedQuery in GraphService yet)
          const ftsResults = await this.searchObjectsFts(
            {
              q: queryText,
              limit,
              organization_id: opts.orgId,
              project_id: opts.projectId,
              type: opts.types?.[0], // Use first type if provided
              label: opts.labels?.[0], // Use first label if provided
              branch_id: opts.branchId,
            },
            ctx
          );

          primaryResults = ftsResults.items;
        } catch (error) {
          this.logger.error(`Search failed: ${(error as Error).message}`);
          return { primaryResults: [], neighbors: {} };
        }

        // Step 2: If neighbors requested, fetch for each primary result
        const neighbors: Record<string, GraphObjectDto[]> = {};

        if (opts.includeNeighbors && primaryResults.length > 0) {
          for (const obj of primaryResults) {
            const neighborIds = new Set<string>();
            const neighborObjects: GraphObjectDto[] = [];

            try {
              // 2a. Get semantically similar objects using searchSimilar
              // This finds objects with similar embedding vectors
              const similarResults = await this.vectorSearch.searchSimilar(
                obj.id,
                {
                  limit: Math.ceil(maxNeighbors / 2), // Split quota between similar and connected
                  maxDistance: opts.maxDistance || 0.5,
                  projectId: opts.projectId,
                  orgId: opts.orgId,
                  branchId: opts.branchId ?? undefined,
                }
              );

              for (const similar of similarResults) {
                if (similar.id !== obj.id) {
                  // Exclude self
                  neighborIds.add(similar.id);
                }
              }

              // 2b. Get directly connected objects via relationships
              const outgoingRels = await this.searchRelationships(
                {
                  src_id: obj.id,
                  limit: maxNeighbors,
                  branch_id: opts.branchId,
                },
                ctx
              );

              const incomingRels = await this.searchRelationships(
                {
                  dst_id: obj.id,
                  limit: maxNeighbors,
                  branch_id: opts.branchId,
                },
                ctx
              );

              for (const rel of outgoingRels.items) {
                neighborIds.add(rel.dst_id);
              }
              for (const rel of incomingRels.items) {
                neighborIds.add(rel.src_id);
              }

              // 2c. Fetch full neighbor objects (limit to maxNeighbors)
              const limitedNeighborIds = Array.from(neighborIds).slice(
                0,
                maxNeighbors
              );
              for (const neighborId of limitedNeighborIds) {
                try {
                  const neighborObj = await this.getObject(neighborId, ctx);
                  if (neighborObj) {
                    neighborObjects.push(neighborObj);
                  }
                } catch (err) {
                  // Skip if neighbor not found or access denied
                  this.logger.debug(
                    `Could not fetch neighbor ${neighborId}: ${
                      (err as Error).message
                    }`
                  );
                }
              }

              neighbors[obj.id] = neighborObjects;
            } catch (error) {
              this.logger.warn(
                `Failed to fetch neighbors for object ${obj.id}: ${
                  (error as Error).message
                }`
              );
              neighbors[obj.id] = []; // Empty array on error
            }
          }
        }

        return {
          primaryResults,
          neighbors,
        };
      }
    );
  }

  async searchRelationships(
    opts: {
      type?: string;
      src_id?: string;
      dst_id?: string;
      limit?: number;
      cursor?: string;
      branch_id?: string | null;
      order?: 'asc' | 'desc';
    },
    ctx?: GraphTenantContext
  ): Promise<{ items: GraphRelationshipDto[]; next_cursor?: string }> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const {
        type,
        src_id,
        dst_id,
        limit = 20,
        cursor,
        branch_id,
        order = 'asc',
      } = opts;
      const headFilters: string[] = [];
      const headParams: any[] = [];
      if (branch_id !== undefined) {
        headParams.push(branch_id ?? null);
        headFilters.push(
          `r.branch_id IS NOT DISTINCT FROM $${headParams.length}`
        );
      }
      const headWhere = headFilters.length
        ? 'WHERE ' + headFilters.join(' AND ')
        : '';
      const baseHead = `SELECT DISTINCT ON (r.canonical_id) r.id, r.project_id, r.branch_id, r.type, r.src_id, r.dst_id, r.properties, r.version, r.supersedes_id, r.canonical_id, r.deleted_at, r.created_at, r.change_summary, r.content_hash
                          FROM kb.graph_relationships r
                          ${headWhere}
                          ORDER BY r.canonical_id, r.version DESC`;
      const outerFilters: string[] = ['h.deleted_at IS NULL'];
      const outerParams: any[] = [...headParams];
      if (type) {
        outerParams.push(type);
        outerFilters.push(`h.type = $${outerParams.length}`);
      }
      if (src_id) {
        outerParams.push(src_id);
        outerFilters.push(`h.src_id = $${outerParams.length}`);
      }
      if (dst_id) {
        outerParams.push(dst_id);
        outerFilters.push(`h.dst_id = $${outerParams.length}`);
      }
      if (cursor) {
        outerParams.push(new Date(cursor));
        if (order === 'desc') {
          outerFilters.push(`h.created_at < $${outerParams.length}`);
        } else {
          outerFilters.push(`h.created_at > $${outerParams.length}`);
        }
      }
      outerParams.push(limit + 1);
      const orderDir = order === 'desc' ? 'DESC' : 'ASC';
      const sql = `SELECT * FROM (${baseHead}) h
                     WHERE ${outerFilters.join(' AND ')}
                     ORDER BY h.created_at ${orderDir}
                     LIMIT $${outerParams.length}`;
      const res = await this.db.query<GraphRelationshipRow>(sql, outerParams);
      let rows = res.rows;
      let next_cursor: string | undefined;
      if (rows.length > limit) {
        rows = rows.slice(0, limit);
      }
      if (rows.length) {
        next_cursor = new Date(
          rows[rows.length - 1].created_at as any
        ).toISOString();
      }
      return { items: rows, next_cursor };
    });
  }

  async listRelationshipHistory(
    id: string,
    limitParam = 20,
    cursor?: string,
    ctx?: GraphTenantContext
  ): Promise<{ items: GraphRelationshipDto[]; next_cursor?: string }> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const limit = Number(limitParam) || 20;
      const base = await this.db.query<{ canonical_id: string }>(
        `SELECT canonical_id FROM kb.graph_relationships WHERE id=$1`,
        [id]
      );
      if (!base.rowCount) throw new NotFoundException('relationship_not_found');
      const canonicalId = base.rows[0].canonical_id;
      const params: any[] = [canonicalId];
      let cursorClause = '';
      if (cursor) {
        // Fast path: determine current head version so a cursor >= head yields empty set per pagination contract
        const head = await this.db.query<{ v: number }>(
          `SELECT version as v FROM kb.graph_relationships WHERE canonical_id=$1 ORDER BY version DESC LIMIT 1`,
          [canonicalId]
        );
        if (head.rowCount && parseInt(cursor, 10) >= head.rows[0].v) {
          if (process.env.NODE_ENV === 'test') {
            // eslint-disable-next-line no-console
            console.log(
              '[history debug][relationship] cursor beyond head -> empty set',
              { cursor, head: head.rows[0].v }
            );
          }
          return { items: [], next_cursor: undefined };
        }
        params.push(cursor);
        cursorClause = ' AND version < $2';
      }
      params.push(limit + 1);
      const res = await this.db.query<GraphRelationshipRow>(
        `SELECT id, project_id, type, src_id, dst_id, properties, version, supersedes_id, canonical_id, deleted_at, created_at, branch_id, change_summary, content_hash
             FROM kb.graph_relationships WHERE canonical_id=$1${cursorClause}
             ORDER BY version DESC
             LIMIT $${params.length}`,
        params
      );
      let next_cursor: string | undefined;
      let rows = res.rows;
      if (rows.length > limit) {
        next_cursor = rows[limit - 1].version?.toString();
        rows = rows.slice(0, limit);
      }
      return { items: rows, next_cursor };
    });
  }

  // ---------------- Phased Traversal (Phase 3) ----------------
  /**
   * Execute multi-phase graph traversal where each phase has its own constraints.
   * Phases run sequentially with each phase starting from nodes discovered by previous phase.
   *
   * @param dto TraverseGraphDto with edgePhases defined
   * @returns GraphTraversalResult with phaseIndex for each node
   */
  private async traversePhased(
    dto: TraverseGraphDto & { branch_id?: string | null }
  ): Promise<GraphTraversalResult> {
    const startTime = performance.now();
    const _start = Date.now();
    const maxNodes = dto.max_nodes ?? 200;
    const maxEdges = dto.max_edges ?? 400;
    const phases = dto.edgePhases!; // Guaranteed to exist by caller check

    // Track all discovered nodes with their phase
    const seen = new Set<string>();
    const gathered: {
      id: string;
      depth: number;
      type: string;
      key?: string | null;
      labels: string[];
      phaseIndex: number;
    }[] = [];
    const edges: {
      id: string;
      type: string;
      src_id: string;
      dst_id: string;
    }[] = [];
    let truncated = false;
    let maxDepthReached = 0;

    // Path tracking (Phase 3: Path Enumeration)
    const trackPaths = dto.returnPaths === true;
    const maxPathsPerNode = dto.maxPathsPerNode ?? 10;
    const pathMap = new Map<string, string[][]>(); // nodeId -> array of paths

    // Phase 0: Process root nodes
    const rootNodes: Array<{
      id: string;
      depth: number;
      type: string;
      key?: string | null;
      labels: string[];
      phaseIndex: number;
    }> = [];

    // Build temporal filter if provided
    const temporalFilter = dto.temporalFilter
      ? buildTemporalFilterClause(dto.temporalFilter, 'o')
      : null;

    for (const rootId of dto.root_ids) {
      if (seen.has(rootId)) continue;

      // Build query with optional temporal filter and expiration filter
      const objectQueryParts: string[] = [
        'SELECT id, type, key, labels, deleted_at, branch_id, properties FROM kb.graph_objects o WHERE id=$1',
      ];
      const objectQueryParams: any[] = [rootId];

      if (temporalFilter) {
        objectQueryParts.push('AND ' + temporalFilter.sqlClause);
        objectQueryParams.push(...temporalFilter.params);
      }

      // Exclude expired objects (Phase 3 Task 7c)
      // Backward compatibility: older minimal schemas may lack expires_at column
      objectQueryParts.push('AND ' + buildExpirationFilterClause('o'));

      let objRes;
      try {
        objRes = await this.db.query<GraphObjectRow>(
          objectQueryParts.join(' '),
          objectQueryParams
        );
      } catch (error: any) {
        if (
          error?.code === '42703' &&
          typeof error?.message === 'string' &&
          error.message.includes('expires_at')
        ) {
          // Retry without expiration filter for backward compatibility
          const partsWithoutExpiration = objectQueryParts.slice(0, -1);
          objRes = await this.db.query<GraphObjectRow>(
            partsWithoutExpiration.join(' '),
            objectQueryParams
          );
        } else {
          throw error;
        }
      }
      if (!objRes.rowCount) continue;
      const row = objRes.rows[0];
      if (
        dto.branch_id !== undefined &&
        row.branch_id !== dto.branch_id &&
        (row.branch_id ?? null) !== (dto.branch_id ?? null)
      )
        continue;
      if (row.deleted_at) continue;
      // Apply node predicate filter (pass properties object for JSON Pointer resolution)
      if (
        dto.nodeFilter &&
        !evaluatePredicates(row.properties || {}, [dto.nodeFilter])
      )
        continue;
      seen.add(row.id);
      const node = {
        id: row.id,
        depth: 0,
        type: row.type,
        key: row.key,
        labels: row.labels,
        phaseIndex: 0,
      };
      rootNodes.push(node);
      gathered.push(node);
      // Track path for root node (path is just itself)
      if (trackPaths) {
        pathMap.set(row.id, [[row.id]]);
      }
      if (gathered.length >= maxNodes) {
        truncated = true;
        break;
      }
    }

    // Execute each phase sequentially
    let phaseStartNodes = rootNodes;
    for (let phaseIdx = 0; phaseIdx < phases.length; phaseIdx++) {
      if (truncated) break;
      const phase = phases[phaseIdx];
      const phaseNum = phaseIdx + 1; // Root nodes are phase 0, first phase is 1

      // Phase-specific filters
      const relTypeFilter = phase.relationshipTypes?.length
        ? new Set(phase.relationshipTypes)
        : undefined;
      const objTypeFilter = phase.objectTypes?.length
        ? new Set(phase.objectTypes)
        : undefined;
      const labelFilter = phase.labels?.length
        ? new Set(phase.labels)
        : undefined;

      // BFS within this phase
      const queue: { id: string; depth: number; path?: string[] }[] =
        phaseStartNodes.map((n) => {
          const paths = trackPaths ? pathMap.get(n.id) : undefined;
          return { id: n.id, depth: 0, path: paths?.[0] }; // Start with first path from phase start node
        });
      const phaseNodes: typeof gathered = [];

      while (queue.length) {
        const current = queue.shift()!;
        // Skip if already processed (can happen if node reached from multiple paths)
        if (current.depth >= phase.maxDepth) continue;

        // Fetch outgoing/ingoing relationships based on phase direction
        const dirClauses: string[] = [];
        const params: any[] = [current.id];

        if (phase.direction === 'out') dirClauses.push('src_id = $1');
        else if (phase.direction === 'in') dirClauses.push('dst_id = $1');
        else dirClauses.push('(src_id = $1 OR dst_id = $1)');

        if (relTypeFilter) {
          const types = Array.from(relTypeFilter);
          params.push(...types);
          dirClauses.push(
            `type = ANY(ARRAY[${types.map((_, i) => '$' + (i + 2)).join(',')}])`
          );
        }

        // Build WHERE clause with optional temporal filter
        const whereClauseParts: string[] = ['h.deleted_at IS NULL'];

        if (dto.branch_id !== undefined) {
          params.push(dto.branch_id ?? null);
          whereClauseParts.push(
            `h.branch_id IS NOT DISTINCT FROM $${params.length}`
          );
        }

        // Add temporal filter for edges if provided
        if (temporalFilter) {
          const edgeTemporalFilter = buildTemporalFilterClause(
            dto.temporalFilter!,
            'h'
          );
          whereClauseParts.push(
            edgeTemporalFilter.sqlClause.replace(
              /\$1/g,
              `$${params.length + 1}`
            )
          );
          params.push(...edgeTemporalFilter.params);
        }

        const edgeSql = `SELECT * FROM (
                    SELECT DISTINCT ON (canonical_id) id, type, src_id, dst_id, deleted_at, version, branch_id, properties${
                      temporalFilter
                        ? ', valid_from, valid_to, created_at, updated_at'
                        : ''
                    }
                    FROM kb.graph_relationships
                    WHERE ${dirClauses.join(' AND ')}
                    ORDER BY canonical_id, version DESC
                ) h
                WHERE ${whereClauseParts.join(' AND ')}
                LIMIT 500`;

        const edgeRes = await this.db.query<GraphRelationshipRow>(
          edgeSql,
          params
        );

        for (const e of edgeRes.rows) {
          // Apply edge predicate filter (pass properties object for JSON Pointer resolution)
          if (
            dto.edgeFilter &&
            !evaluatePredicates(e.properties || {}, [dto.edgeFilter])
          )
            continue;
          if (edges.length >= maxEdges) {
            truncated = true;
            break;
          }
          // Only add edge once
          if (!edges.find((edge) => edge.id === e.id)) {
            edges.push({
              id: e.id,
              type: e.type,
              src_id: e.src_id,
              dst_id: e.dst_id,
            });
          }

          // Determine next node to explore
          const nextId = e.src_id === current.id ? e.dst_id : e.src_id;
          if (seen.has(nextId)) continue; // Skip already seen nodes

          // Fetch and validate next node (with temporal and expiration filters)
          const nextNodeQueryParts: string[] = [
            'SELECT id, type, key, labels, deleted_at, branch_id, properties FROM kb.graph_objects o WHERE id=$1',
          ];
          const nextNodeParams: any[] = [nextId];

          if (temporalFilter) {
            const nodeTemporalFilter = buildTemporalFilterClause(
              dto.temporalFilter!,
              'o'
            );
            nextNodeQueryParts.push(
              'AND ' +
                nodeTemporalFilter.sqlClause.replace(
                  /\$1/g,
                  `$${nextNodeParams.length + 1}`
                )
            );
            nextNodeParams.push(...nodeTemporalFilter.params);
          }

          // Exclude expired objects (Phase 3 Task 7c)
          nextNodeQueryParts.push('AND ' + buildExpirationFilterClause('o'));

          let nextObjRes: any;
          try {
            nextObjRes = await this.db.query<GraphObjectRow>(
              nextNodeQueryParts.join(' '),
              nextNodeParams
            );
          } catch (error: any) {
            if (
              error?.code === '42703' &&
              error.message.includes('expires_at')
            ) {
              // Backward compatibility: retry without expiration filter
              nextNodeQueryParts.pop(); // Remove the expiration clause
              nextObjRes = await this.db.query<GraphObjectRow>(
                nextNodeQueryParts.join(' '),
                nextNodeParams
              );
            } else {
              throw error;
            }
          }
          if (!nextObjRes.rowCount) continue;
          const nextRow = nextObjRes.rows[0];
          if (
            dto.branch_id !== undefined &&
            nextRow.branch_id !== dto.branch_id &&
            (nextRow.branch_id ?? null) !== (dto.branch_id ?? null)
          )
            continue;
          if (nextRow.deleted_at) continue;

          // Track path to this node
          const newPath =
            trackPaths && current.path ? [...current.path, nextId] : undefined;
          const alreadySeen = seen.has(nextId);

          // If node already seen, add alternate path (up to limit)
          if (alreadySeen && trackPaths && newPath) {
            // Prevent circular paths: check if nextId already exists in the path
            const isCircular = current.path && current.path.includes(nextId);
            if (!isCircular) {
              const existingPaths = pathMap.get(nextId) ?? [];
              if (existingPaths.length < maxPathsPerNode) {
                existingPaths.push(newPath);
                pathMap.set(nextId, existingPaths);
              }
            }
            continue; // Don't re-add to results or queue
          }

          if (alreadySeen) continue; // Skip already seen nodes (path tracking disabled)

          // Mark as seen and add to queue (always traverse, even if filtered from results)
          seen.add(nextId);
          const nextDepth = current.depth + 1;

          // Apply phase-specific node filters (for results, but still traverse)
          const passesFilters =
            (!objTypeFilter || objTypeFilter.has(nextRow.type)) &&
            (!labelFilter ||
              nextRow.labels.some((l: string) => labelFilter.has(l))) &&
            (!dto.nodeFilter ||
              evaluatePredicates(nextRow.properties || {}, [dto.nodeFilter]));

          // Add to results only if passes filters
          if (passesFilters) {
            const node = {
              id: nextRow.id,
              depth: nextDepth,
              type: nextRow.type,
              key: nextRow.key,
              labels: nextRow.labels,
              phaseIndex: phaseNum,
            };
            phaseNodes.push(node);
            gathered.push(node);
            maxDepthReached = Math.max(maxDepthReached, nextDepth);

            // Store path for this node
            if (trackPaths && newPath) {
              pathMap.set(nextId, [newPath]);
            }

            if (gathered.length >= maxNodes) {
              truncated = true;
              break;
            }
          }

          // Add to queue for further exploration (regardless of filters)
          if (nextDepth < phase.maxDepth) {
            queue.push({ id: nextId, depth: nextDepth, path: newPath });
          }
        }
        if (truncated) break;
      }

      // Next phase starts from nodes discovered in this phase
      phaseStartNodes = phaseNodes;
      if (phaseStartNodes.length === 0) break; // No nodes to continue from
    }

    // Deterministic ordering: phaseIndex ASC, depth ASC, id ASC
    gathered.sort(
      (a, b) =>
        a.phaseIndex - b.phaseIndex ||
        a.depth - b.depth ||
        a.id.localeCompare(b.id)
    );

    // Pagination (reuse existing pagination logic)
    const limit = dto.limit ?? 50;
    const pageDirection = dto.page_direction ?? 'forward';
    const { decodeTraverseCursor, encodeTraverseCursor } = await import(
      './traverse-cursor.util'
    );
    const decoded = decodeTraverseCursor(dto.cursor);
    let startIndex = 0;
    if (decoded) {
      const idx = gathered.findIndex(
        (n) => n.depth === decoded.d && n.id === decoded.id
      );
      if (idx >= 0) {
        if (pageDirection === 'forward') startIndex = idx + 1;
        else startIndex = Math.max(0, idx - limit);
      }
    }
    let pageItems: typeof gathered;
    if (pageDirection === 'forward') {
      pageItems = gathered.slice(startIndex, startIndex + limit);
    } else {
      const cursorIdx = decoded
        ? gathered.findIndex(
            (n) => n.depth === decoded.d && n.id === decoded.id
          )
        : -1;
      const sliceEnd = cursorIdx >= 0 ? cursorIdx : 0;
      const raw = gathered.slice(
        Math.max(0, startIndex),
        sliceEnd >= 0 ? sliceEnd : undefined
      );
      pageItems = raw.slice(-limit);
    }

    const first = pageItems[0];
    const last = pageItems[pageItems.length - 1];
    const hasPrevious =
      !!first &&
      !(first.depth === gathered[0]?.depth && first.id === gathered[0]?.id);
    const hasNext =
      !!last &&
      !(
        last.depth === gathered[gathered.length - 1]?.depth &&
        last.id === gathered[gathered.length - 1]?.id
      );
    const nextCursor =
      hasNext && last ? encodeTraverseCursor(last.depth, last.id) : null;
    const prevCursor =
      hasPrevious && first ? encodeTraverseCursor(first.depth, first.id) : null;
    const approxStart = first
      ? gathered.findIndex((n) => n.id === first.id && n.depth === first.depth)
      : 0;
    const approxEnd = last
      ? gathered.findIndex((n) => n.id === last.id && n.depth === last.depth)
      : 0;

    // Add paths to result nodes if requested
    const resultNodes = trackPaths
      ? pageItems.map((n) => ({
          ...n,
          paths: pathMap.get(n.id) ?? [],
        }))
      : pageItems;

    const result: GraphTraversalResult = {
      roots: dto.root_ids,
      nodes: resultNodes,
      edges,
      truncated,
      max_depth_reached: maxDepthReached,
      total_nodes: gathered.length,
      has_next_page: hasNext,
      has_previous_page: hasPrevious,
      next_cursor: nextCursor,
      previous_cursor: prevCursor,
      approx_position_start: approxStart,
      approx_position_end: approxEnd,
      page_direction: pageDirection,
      query_time_ms: Math.round((performance.now() - startTime) * 100) / 100,
      result_count: gathered.length,
    };

    // Apply field pruning if requested (Phase 3: Field Pruning)
    const fieldStrategy = (dto.fieldStrategy || 'full') as FieldStrategy;
    return pruneGraphResult(result, fieldStrategy);
  }

  // ---------------- Traversal ----------------
  async traverse(
    dto: TraverseGraphDto & { branch_id?: string | null },
    ctx?: GraphTenantContext
  ): Promise<GraphTraversalResult> {
    return this.runWithRequestContext(ctx, undefined, undefined, () =>
      this.traverseInternal(dto)
    );
  }

  private async traverseInternal(
    dto: TraverseGraphDto & { branch_id?: string | null }
  ): Promise<GraphTraversalResult> {
    const startTime = performance.now();

    // PHASE 3: Dispatch to phased traversal if edgePhases provided
    if (dto.edgePhases && dto.edgePhases.length > 0) {
      return this.traversePhased(dto);
    }

    // Legacy traversal (backward compatible)
    const _start = Date.now();
    const direction = dto.direction || 'both';
    const maxDepth = dto.max_depth ?? 2;
    const maxNodes = dto.max_nodes ?? 200;
    const maxEdges = dto.max_edges ?? 400;
    const relTypeFilter = dto.relationship_types?.length
      ? new Set(dto.relationship_types)
      : undefined;
    const objTypeFilter = dto.object_types?.length
      ? new Set(dto.object_types)
      : undefined;
    const labelFilter = dto.labels?.length ? new Set(dto.labels) : undefined;

    // Path tracking (Phase 3: Path Enumeration)
    const trackPaths = dto.returnPaths === true;
    const maxPathsPerNode = dto.maxPathsPerNode ?? 10;
    const pathMap = new Map<string, string[][]>(); // nodeId -> array of paths

    // Build temporal filter if provided (Phase 3: Temporal Filtering)
    const temporalFilter = dto.temporalFilter
      ? buildTemporalFilterClause(dto.temporalFilter, 'o')
      : null;

    // Perform traversal first (unpaged) honoring expansion limits
    const queue: { id: string; depth: number; path?: string[] }[] =
      dto.root_ids.map((id) => ({
        id,
        depth: 0,
        path: trackPaths ? [id] : undefined,
      }));
    const seen = new Set<string>();
    const queued = new Set<string>(dto.root_ids); // Track nodes already in queue
    const gathered: {
      id: string;
      depth: number;
      type: string;
      key?: string | null;
      labels: string[];
    }[] = [];
    const edges: {
      id: string;
      type: string;
      src_id: string;
      dst_id: string;
    }[] = [];
    let truncated = false;
    let maxDepthReached = 0;

    while (queue.length) {
      const current = queue.shift()!;

      // Track path to current node
      if (trackPaths && current.path) {
        const existingPaths = pathMap.get(current.id) ?? [];
        // Add this path if it's not already present (avoid duplicates) and under limit
        if (existingPaths.length < maxPathsPerNode) {
          const pathExists = existingPaths.some(
            (p) =>
              p.length === current.path!.length &&
              p.every((id, i) => id === current.path![i])
          );
          if (!pathExists) {
            existingPaths.push(current.path);
            pathMap.set(current.id, existingPaths);
          }
        }
      }

      if (seen.has(current.id)) continue;
      seen.add(current.id);

      // Build object query with temporal filter and expiration filter
      const objQueryParts: string[] = [
        'SELECT id, type, key, labels, deleted_at, branch_id, properties FROM kb.graph_objects o WHERE id=$1',
      ];
      const objQueryParams: any[] = [current.id];

      if (temporalFilter) {
        objQueryParts.push(
          'AND ' +
            temporalFilter.sqlClause.replace(
              /\$1/g,
              `$${objQueryParams.length + 1}`
            )
        );
        objQueryParams.push(...temporalFilter.params);
      }

      // Exclude expired objects (Phase 3 Task 7c)
      objQueryParts.push('AND ' + buildExpirationFilterClause('o'));

      let objRes: any;
      try {
        objRes = await this.db.query<GraphObjectRow>(
          objQueryParts.join(' '),
          objQueryParams
        );
      } catch (error: any) {
        if (error?.code === '42703' && error.message.includes('expires_at')) {
          // Backward compatibility: retry without expiration filter
          objQueryParts.pop(); // Remove the expiration clause
          objRes = await this.db.query<GraphObjectRow>(
            objQueryParts.join(' '),
            objQueryParams
          );
        } else {
          throw error;
        }
      }
      if (!objRes.rowCount) continue;
      const row = objRes.rows[0];
      if (
        (dto as any).branch_id !== undefined &&
        row.branch_id !== (dto as any).branch_id &&
        (row.branch_id ?? null) !== ((dto as any).branch_id ?? null)
      )
        continue;
      if (row.deleted_at) continue;
      if (objTypeFilter && !objTypeFilter.has(row.type)) continue;
      if (labelFilter && !row.labels.some((l: string) => labelFilter.has(l)))
        continue;
      // Apply node predicate filter (pass properties object for JSON Pointer resolution)
      if (
        dto.nodeFilter &&
        !evaluatePredicates(row.properties || {}, [dto.nodeFilter])
      )
        continue;
      gathered.push({
        id: row.id,
        depth: current.depth,
        type: row.type,
        key: row.key,
        labels: row.labels,
      });
      maxDepthReached = Math.max(maxDepthReached, current.depth);
      if (gathered.length >= maxNodes) {
        truncated = true;
        break;
      }
      if (current.depth >= maxDepth) continue;

      // Build edge query
      const dirClauses: string[] = [];
      const params: any[] = [current.id];
      if (direction === 'out') dirClauses.push('src_id = $1');
      else if (direction === 'in') dirClauses.push('dst_id = $1');
      else dirClauses.push('(src_id = $1 OR dst_id = $1)');
      if (relTypeFilter) {
        const types = Array.from(relTypeFilter);
        params.push(...types);
        dirClauses.push(
          `type = ANY(ARRAY[${types.map((_, i) => '$' + (i + 2)).join(',')}])`
        );
      }

      // Build WHERE clause with optional temporal filter
      const edgeWhereClauseParts: string[] = ['h.deleted_at IS NULL'];

      if (dto.branch_id !== undefined) {
        params.push((dto as any).branch_id ?? null);
        edgeWhereClauseParts.push(
          `h.branch_id IS NOT DISTINCT FROM $${params.length}`
        );
      }

      // Add temporal filter for edges if provided
      if (temporalFilter) {
        const edgeTemporalFilter = buildTemporalFilterClause(
          dto.temporalFilter!,
          'h'
        );
        edgeWhereClauseParts.push(
          edgeTemporalFilter.sqlClause.replace(/\$1/g, `$${params.length + 1}`)
        );
        params.push(...edgeTemporalFilter.params);
      }

      const edgeSql = `SELECT * FROM (
                                          SELECT DISTINCT ON (canonical_id) id, type, src_id, dst_id, deleted_at, version, branch_id, properties${
                                            temporalFilter
                                              ? ', valid_from, valid_to, created_at, updated_at'
                                              : ''
                                          }
                                          FROM kb.graph_relationships
                                          WHERE ${dirClauses.join(' AND ')}
                                          ORDER BY canonical_id, version DESC
                                      ) h
                                      WHERE ${edgeWhereClauseParts.join(
                                        ' AND '
                                      )}
                                      LIMIT 500`;

      const edgeRes = await this.db.query<GraphRelationshipRow>(
        edgeSql,
        params
      );
      for (const e of edgeRes.rows) {
        // Apply edge predicate filter (pass properties object for JSON Pointer resolution)
        if (
          dto.edgeFilter &&
          !evaluatePredicates(e.properties || {}, [dto.edgeFilter])
        )
          continue;
        if (edges.length >= maxEdges) {
          truncated = true;
          break;
        }
        edges.push({
          id: e.id,
          type: e.type,
          src_id: e.src_id,
          dst_id: e.dst_id,
        });
        const nextId = e.src_id === current.id ? e.dst_id : e.src_id;

        // Track path or handle multiple paths
        const newPath =
          trackPaths && current.path ? [...current.path, nextId] : undefined;

        // Check if node is already queued or seen
        const alreadyQueued = queued.has(nextId);
        const alreadySeen = seen.has(nextId);

        if (alreadyQueued || alreadySeen) {
          // Node already queued or seen - add alternate path (up to limit)
          if (trackPaths && newPath) {
            // Prevent circular paths: check if nextId already exists in the path
            const isCircular = current.path && current.path.includes(nextId);
            if (!isCircular) {
              const existingPaths = pathMap.get(nextId) ?? [];
              if (existingPaths.length < maxPathsPerNode) {
                existingPaths.push(newPath);
                pathMap.set(nextId, existingPaths);
              }
            }
          }
        } else {
          // New node - add to queue
          queued.add(nextId);
          queue.push({ id: nextId, depth: current.depth + 1, path: newPath });
        }
      }
      if (truncated) break;
    }

    // Deterministic ordering: depth ASC, id ASC
    gathered.sort((a, b) => a.depth - b.depth || a.id.localeCompare(b.id));

    // Pagination window
    const limit = dto.limit ?? 50;
    const pageDirection = dto.page_direction ?? 'forward';
    const { decodeTraverseCursor, encodeTraverseCursor } = await import(
      './traverse-cursor.util'
    );
    const decoded = decodeTraverseCursor(dto.cursor);
    let startIndex = 0;
    if (decoded) {
      const idx = gathered.findIndex(
        (n) => n.depth === decoded.d && n.id === decoded.id
      );
      if (idx >= 0) {
        if (pageDirection === 'forward') startIndex = idx + 1;
        else startIndex = Math.max(0, idx - limit);
      }
    }
    let pageItems: typeof gathered;
    if (pageDirection === 'forward') {
      pageItems = gathered.slice(startIndex, startIndex + limit);
    } else {
      const cursorIdx = decoded
        ? gathered.findIndex(
            (n) => n.depth === decoded.d && n.id === decoded.id
          )
        : -1;
      const sliceEnd = cursorIdx >= 0 ? cursorIdx : 0; // exclusive
      const raw = gathered.slice(
        Math.max(0, startIndex),
        sliceEnd >= 0 ? sliceEnd : undefined
      );
      pageItems = raw.slice(-limit); // last N to keep ascending order
    }
    const first = pageItems[0];
    const last = pageItems[pageItems.length - 1];
    const hasPrevious =
      !!first &&
      !(first.depth === gathered[0]?.depth && first.id === gathered[0]?.id);
    const hasNext =
      !!last &&
      !(
        last.depth === gathered[gathered.length - 1]?.depth &&
        last.id === gathered[gathered.length - 1]?.id
      );
    const nextCursor =
      hasNext && last ? encodeTraverseCursor(last.depth, last.id) : null;
    const prevCursor =
      hasPrevious && first ? encodeTraverseCursor(first.depth, first.id) : null;
    const approxStart = first
      ? gathered.findIndex((n) => n.id === first.id && n.depth === first.depth)
      : 0;
    const approxEnd = last
      ? gathered.findIndex((n) => n.id === last.id && n.depth === last.depth)
      : 0;
    // Telemetry emission for traversal pagination (Phase 1 telemetry item)
    try {
      const evt = {
        type: 'graph.traverse.page',
        roots_count: dto.root_ids.length,
        direction: direction,
        page_direction: pageDirection,
        requested_limit: dto.limit ?? 50,
        effective_limit: limit,
        total_nodes: gathered.length,
        page_item_count: pageItems.length,
        has_next_page: hasNext,
        has_previous_page: hasPrevious,
        max_depth_requested: maxDepth,
        max_depth_reached: maxDepthReached,
        truncated,
        approx_position_start: approxStart,
        approx_position_end: approxEnd,
        next_cursor_set: !!nextCursor,
        prev_cursor_set: !!prevCursor,
        elapsed_ms: Date.now() - _start,
        ts: Date.now(),
      };
      // Store on a lightweight in-memory holder (mirrors search pattern if added later)
      // @ts-ignore add ad-hoc bag
      if (!this.telemetry) this.telemetry = { traverseEvents: 0 };
      // @ts-ignore
      this.telemetry.traverseEvents++;
      // @ts-ignore
      this.telemetry.lastTraverse = evt;
      if (process.env.GRAPH_TRAVERSE_TELEMETRY_LOG?.toLowerCase() === 'true') {
        // eslint-disable-next-line no-console
        console.log('[telemetry]', evt);
      }
    } catch {
      /* swallow errors  telemetry must never break traversal */
    }

    // Add paths to result nodes if requested (Phase 3: Path Enumeration)
    const resultNodes = trackPaths
      ? pageItems.map((n) => ({
          ...n,
          paths: pathMap.get(n.id) ?? [],
        }))
      : pageItems;

    const result: GraphTraversalResult = {
      roots: dto.root_ids,
      nodes: resultNodes,
      edges,
      truncated,
      max_depth_reached: maxDepthReached,
      total_nodes: gathered.length,
      has_next_page: hasNext,
      has_previous_page: hasPrevious,
      next_cursor: nextCursor,
      previous_cursor: prevCursor,
      approx_position_start: approxStart,
      approx_position_end: approxEnd,
      page_direction: pageDirection,
    };

    // Apply field pruning if requested (Phase 3: Field Pruning)
    const fieldStrategy = (dto.fieldStrategy || 'full') as FieldStrategy;
    return pruneGraphResult(result, fieldStrategy);
  }

  // ---------------- Expand (single-pass richer traversal) ----------------
  async expand(
    dto: any & { branch_id?: string | null },
    ctx?: GraphTenantContext
  ): Promise<{
    roots: string[];
    nodes: any[];
    edges: any[];
    truncated: boolean;
    max_depth_reached: number;
    total_nodes: number;
    meta: any;
  }> {
    return this.runWithRequestContext(ctx, undefined, undefined, () =>
      this.expandInternal(dto)
    );
  }

  private async expandInternal(
    dto: any & { branch_id?: string | null }
  ): Promise<{
    roots: string[];
    nodes: any[];
    edges: any[];
    truncated: boolean;
    max_depth_reached: number;
    total_nodes: number;
    meta: any;
  }> {
    const start = Date.now();
    const direction: 'out' | 'in' | 'both' = dto.direction || 'both';
    const maxDepth = dto.max_depth ?? 2;
    const maxNodes = dto.max_nodes ?? 400;
    const maxEdges = dto.max_edges ?? 800;
    const relTypeFilter = dto.relationship_types?.length
      ? new Set(dto.relationship_types)
      : undefined;
    const objTypeFilter = dto.object_types?.length
      ? new Set(dto.object_types)
      : undefined;
    const labelFilter = dto.labels?.length ? new Set(dto.labels) : undefined;
    const includeRelProps = !!dto.include_relationship_properties;
    const projection = dto.projection as
      | {
          include_object_properties?: string[];
          exclude_object_properties?: string[];
        }
      | undefined;
    const includeKeys = projection?.include_object_properties
      ? new Set(projection.include_object_properties)
      : undefined;
    const excludeKeys = projection?.exclude_object_properties
      ? new Set(projection.exclude_object_properties)
      : undefined;

    const queue: { id: string; depth: number }[] = dto.root_ids.map(
      (r: string) => ({ id: r, depth: 0 })
    );
    const seen = new Set<string>();
    const nodes: any[] = [];
    const edges: any[] = [];
    let truncated = false;
    let maxDepthReached = 0;

    while (queue.length) {
      const current = queue.shift()!;
      if (seen.has(current.id)) continue;
      seen.add(current.id);
      const objRes = await this.db.query<GraphObjectRow>(
        `SELECT id, type, key, labels, properties, deleted_at, branch_id FROM kb.graph_objects WHERE id=$1`,
        [current.id]
      );
      if (!objRes.rowCount) continue;
      const row = objRes.rows[0];
      if (
        dto.branch_id !== undefined &&
        row.branch_id !== (dto.branch_id ?? null)
      )
        continue;
      if (row.deleted_at) continue;
      if (objTypeFilter && !objTypeFilter.has(row.type)) continue;
      if (labelFilter && !row.labels.some((l: string) => labelFilter.has(l)))
        continue;
      // Projection filter (shallow keys only for now)
      let props: Record<string, any> | undefined = row.properties as any;
      if (includeKeys && props) {
        const filtered: Record<string, any> = {};
        for (const k of includeKeys)
          if (k in props) filtered[k] = (props as any)[k];
        props = filtered;
      }
      if (excludeKeys && props) {
        for (const k of excludeKeys) delete props[k];
      }
      nodes.push({
        id: row.id,
        depth: current.depth,
        type: row.type,
        key: row.key,
        labels: row.labels,
        properties: props,
      });
      maxDepthReached = Math.max(maxDepthReached, current.depth);
      if (nodes.length >= maxNodes) {
        truncated = true;
        break;
      }
      if (current.depth >= maxDepth) continue;
      const dirClauses: string[] = [];
      const params: any[] = [current.id];
      if (direction === 'out') dirClauses.push('src_id = $1');
      else if (direction === 'in') dirClauses.push('dst_id = $1');
      else dirClauses.push('(src_id = $1 OR dst_id = $1)');
      if (relTypeFilter) {
        const types = Array.from(relTypeFilter);
        params.push(...types);
        dirClauses.push(
          `type = ANY(ARRAY[${types.map((_, i) => '$' + (i + 2)).join(',')}])`
        );
      }
      const edgeSql = `SELECT * FROM (
                                          SELECT DISTINCT ON (canonical_id) id, type, src_id, dst_id, properties, deleted_at, version, branch_id
                                          FROM kb.graph_relationships
                                          WHERE ${dirClauses.join(' AND ')}
                                          ORDER BY canonical_id, version DESC
                                      ) h
                                      WHERE h.deleted_at IS NULL
                                      ${
                                        dto.branch_id !== undefined
                                          ? 'AND h.branch_id IS NOT DISTINCT FROM $' +
                                            (params.length + 1)
                                          : ''
                                      }
                                      LIMIT 1000`;
      if (dto.branch_id !== undefined) params.push(dto.branch_id ?? null);
      const edgeRes = await this.db.query<GraphRelationshipRow>(
        edgeSql,
        params
      );
      for (const e of edgeRes.rows) {
        if (edges.length >= maxEdges) {
          truncated = true;
          break;
        }
        edges.push(
          includeRelProps
            ? {
                id: e.id,
                type: e.type,
                src_id: e.src_id,
                dst_id: e.dst_id,
                properties: e.properties,
              }
            : { id: e.id, type: e.type, src_id: e.src_id, dst_id: e.dst_id }
        );
        const nextId = e.src_id === current.id ? e.dst_id : e.src_id;
        if (!seen.has(nextId))
          queue.push({ id: nextId, depth: current.depth + 1 });
      }
      if (truncated) break;
    }

    nodes.sort((a, b) => a.depth - b.depth || a.id.localeCompare(b.id));
    const meta = {
      requested: {
        max_depth: maxDepth,
        max_nodes: maxNodes,
        max_edges: maxEdges,
        direction,
      },
      node_count: nodes.length,
      edge_count: edges.length,
      truncated,
      max_depth_reached: maxDepthReached,
      elapsed_ms: Date.now() - start,
      filters: {
        relationship_types: relTypeFilter
          ? Array.from(relTypeFilter)
          : undefined,
        object_types: objTypeFilter ? Array.from(objTypeFilter) : undefined,
        labels: labelFilter ? Array.from(labelFilter) : undefined,
        projection: projection
          ? {
              include: includeKeys ? Array.from(includeKeys) : undefined,
              exclude: excludeKeys ? Array.from(excludeKeys) : undefined,
            }
          : undefined,
        include_relationship_properties: includeRelProps || undefined,
      },
    };

    // Telemetry
    try {
      const evt = {
        type: 'graph.expand',
        ...meta,
        roots_count: dto.root_ids.length,
        ts: Date.now(),
      };
      // @ts-ignore
      if (!this.telemetry) this.telemetry = { expandEvents: 0 };
      // @ts-ignore
      this.telemetry.expandEvents = (this.telemetry.expandEvents || 0) + 1;
      // @ts-ignore
      this.telemetry.lastExpand = evt;
      if (process.env.GRAPH_EXPAND_TELEMETRY_LOG?.toLowerCase() === 'true') {
        // eslint-disable-next-line no-console
        console.log('[telemetry]', evt);
      }
    } catch {
      /* swallow */
    }

    return {
      roots: dto.root_ids,
      nodes,
      edges,
      truncated,
      max_depth_reached: maxDepthReached,
      total_nodes: nodes.length,
      meta,
    };
  }

  // ---------------- Branch Merge (Dry-Run MVP) ----------------
  async mergeBranchDryRun(
    targetBranchId: string,
    dto: BranchMergeRequestDto,
    ctx?: GraphTenantContext
  ): Promise<BranchMergeSummaryDto> {
    return this.runWithRequestContext(ctx, undefined, undefined, async () => {
      const sourceBranchId = dto.sourceBranchId;
      if (sourceBranchId === targetBranchId) {
        return {
          targetBranchId,
          sourceBranchId,
          dryRun: true,
          total_objects: 0,
          unchanged_count: 0,
          added_count: 0,
          fast_forward_count: 0,
          conflict_count: 0,
          objects: [],
        };
      }
      // Branch validation
      const branches = await this.db.query<{ id: string }>(
        `SELECT id FROM kb.branches WHERE id = ANY($1::uuid[])`,
        [[targetBranchId, sourceBranchId]]
      );
      if (branches.rowCount !== 2) {
        throw new NotFoundException('branch_not_found');
      }
      // Determine lineage relationship (is source an ancestor of target, or vice versa?)
      let sourceIsAncestor = false;
      let targetIsAncestor = false;
      try {
        const lineageRes = await this.db.query<{ ancestor_branch_id: string }>(
          `SELECT ancestor_branch_id FROM kb.branch_lineage WHERE branch_id = $1`,
          [targetBranchId]
        );
        if (lineageRes.rowCount) {
          sourceIsAncestor = lineageRes.rows.some(
            (r) => r.ancestor_branch_id === sourceBranchId
          );
        }
        const reverseLineageRes = await this.db.query<{
          ancestor_branch_id: string;
        }>(
          `SELECT ancestor_branch_id FROM kb.branch_lineage WHERE branch_id = $1`,
          [sourceBranchId]
        );
        if (reverseLineageRes.rowCount) {
          targetIsAncestor = reverseLineageRes.rows.some(
            (r) => r.ancestor_branch_id === targetBranchId
          );
        }
      } catch {
        /* lineage optional; classification will fallback */
      }

      // Hard limits
      const HARD_LIMIT = parseInt(
        process.env.GRAPH_MERGE_ENUM_HARD_LIMIT || '500',
        10
      );
      const requestedLimit =
        dto.limit && dto.limit > 0
          ? Math.min(dto.limit, HARD_LIMIT)
          : HARD_LIMIT;

      // Strategy (simplified MVP):
      // 1. Select heads (latest versions) per canonical_id for both branches.
      // 2. Full outer join on canonical_id to see presence & compare change summaries & hashes.
      // 3. Classify.
      // NOTE: LCA / ancestor logic omitted in MVP; we treat any difference in content_hash as divergence.

      // NOTE: Current implementation does not propagate canonical_id across branches when creating the
      // same (type,key) logical object independently. To surface meaningful merge semantics (incl. conflicts)
      // we treat objects sharing (type,key) across branches as the same logical identity even if their
      // canonical_id differs. This broadened join lets us classify Added vs Conflict instead of two independent
      // rows (target-only + source-only). In future when true branching copies canonical history (shared
      // canonical_id) this OR condition remains valid but typically resolves on the canonical_id equality.
      const sql = `WITH tgt AS (
                        SELECT DISTINCT ON (canonical_id) canonical_id, id, type, key, content_hash, change_summary, properties
                        FROM kb.graph_objects
                        WHERE branch_id = $1
                        ORDER BY canonical_id, version DESC
                     ), src AS (
                        SELECT DISTINCT ON (canonical_id) canonical_id, id, type, key, content_hash, change_summary, properties
                        FROM kb.graph_objects
                        WHERE branch_id = $2
                        ORDER BY canonical_id, version DESC
                     )
                     SELECT COALESCE(tgt.canonical_id, src.canonical_id) as canonical_id,
                            tgt.id as target_id,
                            src.id as source_id,
                            tgt.content_hash as target_hash,
                            src.content_hash as source_hash,
                            tgt.change_summary as target_change,
                            src.change_summary as source_change,
                            tgt.properties as target_props,
                            src.properties as source_props,
                            tgt.type as target_type,
                            src.type as source_type,
                            tgt.key as target_key,
                            src.key as source_key
                     FROM tgt
                     FULL OUTER JOIN src ON tgt.canonical_id = src.canonical_id
                     LIMIT $3`;
      const res = await this.db.query<any>(sql, [
        targetBranchId,
        sourceBranchId,
        requestedLimit + 1,
      ]);
      let rows = pairIndependentHeads(res.rows);
      const truncated = rows.length > requestedLimit;
      const effectiveRows = truncated ? rows.slice(0, requestedLimit) : rows;

      const objects: BranchMergeObjectSummaryDto[] = [];
      let unchanged = 0,
        added = 0,
        ff = 0,
        conflict = 0;
      for (const r of effectiveRows) {
        const canonicalId = r.canonical_id;
        const sourceHeadId = r.source_id || null;
        const targetHeadId = r.target_id || null;
        if (process.env.GRAPH_MERGE_ORDERING_DEBUG?.toLowerCase() === 'true') {
          // eslint-disable-next-line no-console
          console.log('[merge-debug] row pre-classify', {
            target_key: r.target_key,
            source_key: r.source_key,
            target_hash: r.target_hash,
            source_hash: r.source_hash,
            target_change_paths: r.target_change?.paths,
            source_change_paths: r.source_change?.paths,
          });
        }
        let status: BranchMergeObjectStatus;
        let sourcePaths: string[] = [];
        let targetPaths: string[] = [];
        let conflicts: string[] | undefined;
        if (sourceHeadId && !targetHeadId) {
          status = BranchMergeObjectStatus.Added;
          added++;
          sourcePaths = r.source_change?.paths || ['/'];
        } else if (!sourceHeadId && targetHeadId) {
          // Exists only on target  treat as unchanged (no action needed)
          status = BranchMergeObjectStatus.Unchanged;
          unchanged++;
          targetPaths = r.target_change?.paths || ['/'];
        } else if (sourceHeadId && targetHeadId) {
          // IMPORTANT: content_hash is stored as BYTEA in Postgres so node-postgres returns Buffer objects.
          // Direct reference equality (===) on Buffers will almost always be false even when the underlying
          // bytes are identical. This previously caused identical objects to be misclassified as conflicts
          // (overlapping path sets) instead of 'unchanged'. We perform a byte/content comparison here.
          const hashesEqual = (() => {
            const a = r.source_hash as any;
            const b = r.target_hash as any;
            if (!a || !b) return false;
            if (Buffer.isBuffer(a) && Buffer.isBuffer(b))
              return (a as Buffer).equals(b as Buffer);
            return String(a) === String(b);
          })();
          if (hashesEqual) {
            status = BranchMergeObjectStatus.Unchanged;
            unchanged++;
          } else {
            // Compare changed paths intersection; if overlapping paths differ -> conflict else fast-forward
            sourcePaths = r.source_change?.paths || ['/'];
            targetPaths = r.target_change?.paths || ['/'];
            // Lineage fast-forward override: if source branch is an ancestor of target branch, any differing object
            // whose target head exists is treated as FastForward (the target diverged; source provides newer additions) unless
            // overlapping changed path sets indicate conflicting edits post-fork. This is a heuristic pending full 3-way base.
            // Superset fast-forward heuristic: if target properties are a subset of source with identical values
            // (i.e., source only adds new properties), treat as fast-forward even though change path sets overlap.
            try {
              const targetProps: Record<string, any> = r.target_props || {};
              const sourceProps: Record<string, any> = r.source_props || {};
              const targetKeys = Object.keys(targetProps);
              const superset = targetKeys.every(
                (k) =>
                  Object.prototype.hasOwnProperty.call(sourceProps, k) &&
                  JSON.stringify(sourceProps[k]) ===
                    JSON.stringify(targetProps[k])
              );
              if (
                superset &&
                Object.keys(sourceProps).some(
                  (k) => !Object.prototype.hasOwnProperty.call(targetProps, k)
                )
              ) {
                status = BranchMergeObjectStatus.FastForward;
                ff++;
              } else {
                const setA = new Set(sourcePaths);
                const overlap = targetPaths.filter((p: string) => setA.has(p));
                if (overlap.length) {
                  if (sourceIsAncestor) {
                    // Ancestor override: treat as fast-forward despite overlap (we assume target modifications are descendants of source)
                    status = BranchMergeObjectStatus.FastForward;
                    ff++;
                  } else {
                    status = BranchMergeObjectStatus.Conflict;
                    conflict++;
                    conflicts = overlap.sort();
                  }
                } else {
                  status = BranchMergeObjectStatus.FastForward;
                  ff++;
                }
              }
            } catch {
              const setA = new Set(sourcePaths);
              const overlap = targetPaths.filter((p: string) => setA.has(p));
              if (overlap.length) {
                if (sourceIsAncestor) {
                  status = BranchMergeObjectStatus.FastForward;
                  ff++;
                } else {
                  status = BranchMergeObjectStatus.Conflict;
                  conflict++;
                  conflicts = overlap.sort();
                }
              } else {
                status = BranchMergeObjectStatus.FastForward;
                ff++;
              }
            }
          }
        } else {
          // Should not happen (no head in either branch), skip
          continue;
        }
        objects.push({
          canonical_id: canonicalId,
          status,
          source_head_id: sourceHeadId,
          target_head_id: targetHeadId,
          source_paths: sourcePaths,
          target_paths: targetPaths,
          conflicts,
        });
      }

      // Deterministic ordering (stable across runs for same dataset):
      // Priority by status: conflict (0) -> fast_forward (1) -> added (2) -> unchanged (3)
      // Within same status bucket: order by canonical_id ascending to avoid flakiness.
      const statusPriority: Record<BranchMergeObjectStatus, number> = {
        [BranchMergeObjectStatus.Conflict]: 0,
        [BranchMergeObjectStatus.FastForward]: 1,
        [BranchMergeObjectStatus.Added]: 2,
        [BranchMergeObjectStatus.Unchanged]: 3,
      } as const;
      // Bucket-based deterministic ordering (avoids relying solely on comparator correctness across environments).
      const bucketMap: Record<number, BranchMergeObjectSummaryDto[]> = {
        0: [],
        1: [],
        2: [],
        3: [],
      };
      for (const o of objects) {
        const p = statusPriority[o.status];
        (bucketMap[p ?? 3] ||= []).push(o);
      }
      for (const p of Object.keys(bucketMap)) {
        bucketMap[p as any].sort((a, b) =>
          a.canonical_id.localeCompare(b.canonical_id)
        );
      }
      const reordered = [
        ...bucketMap[0],
        ...bucketMap[1],
        ...bucketMap[2],
        ...bucketMap[3],
      ];
      objects.splice(0, objects.length, ...reordered);
      // Fallback defensive comparator (should be no-op if bucket ordering already correct)  ensures any later mutation keeps order stable.
      objects.sort((a, b) => {
        const pa = statusPriority[a.status];
        const pb = statusPriority[b.status];
        if (pa !== pb) return pa - pb;
        return a.canonical_id.localeCompare(b.canonical_id);
      });
      // Attach debug priority always (harmless) so tests can introspect even if NODE_ENV mismatch.
      const dbgPriority: Record<BranchMergeObjectStatus, number> =
        statusPriority;
      for (const o of objects) {
        // @ts-ignore debug field (non-spec)
        o.debug_priority = dbgPriority[o.status];
      }
      // Optional verbose ordering log (enable via GRAPH_MERGE_ORDERING_DEBUG=true)
      if (process.env.GRAPH_MERGE_ORDERING_DEBUG?.toLowerCase() === 'true') {
        // eslint-disable-next-line no-console
        console.log(
          'AT-MERGE ordering final statuses',
          objects.map((o) => o.status),
          'priorities',
          objects.map((o) => (o as any).debug_priority)
        );
      }
      // Enumerate relationships (parallel logic) BEFORE apply so we can apply relationship changes too
      const relSql = `WITH tgt AS (
                            SELECT DISTINCT ON (canonical_id) canonical_id, id, type, src_id, dst_id, content_hash, change_summary, properties
                            FROM kb.graph_relationships
                            WHERE branch_id = $1
                            ORDER BY canonical_id, version DESC
                         ), src AS (
                            SELECT DISTINCT ON (canonical_id) canonical_id, id, type, src_id, dst_id, content_hash, change_summary, properties
                            FROM kb.graph_relationships
                            WHERE branch_id = $2
                            ORDER BY canonical_id, version DESC
                         )
                         SELECT COALESCE(tgt.canonical_id, src.canonical_id) as canonical_id,
                                tgt.id as target_id,
                                src.id as source_id,
                                tgt.content_hash as target_hash,
                                src.content_hash as source_hash,
                                tgt.change_summary as target_change,
                                src.change_summary as source_change,
                                tgt.properties as target_props,
                                src.properties as source_props,
                                tgt.type as target_type,
                                src.type as source_type,
                                tgt.src_id as target_src_id,
                                tgt.dst_id as target_dst_id,
                                src.src_id as source_src_id,
                                src.dst_id as source_dst_id
                         FROM tgt
                         FULL OUTER JOIN src ON tgt.canonical_id = src.canonical_id
                         LIMIT $3`;
      const relRes = await this.db.query<any>(relSql, [
        targetBranchId,
        sourceBranchId,
        requestedLimit + 1,
      ]);
      let relRows = pairIndependentRelationshipHeads(relRes.rows);
      const relTruncated = relRows.length > requestedLimit;
      const effectiveRelRows = relTruncated
        ? relRows.slice(0, requestedLimit)
        : relRows;
      const relationships: BranchMergeRelationshipSummaryDto[] = [];
      let rUnchanged = 0,
        rAdded = 0,
        rFF = 0,
        rConflict = 0;
      for (const r of effectiveRelRows) {
        const sourceHeadId = r.source_id || null;
        const targetHeadId = r.target_id || null;
        let status: BranchMergeRelationshipStatus;
        let sourcePaths: string[] = [];
        let targetPaths: string[] = [];
        let conflicts: string[] | undefined;
        if (sourceHeadId && !targetHeadId) {
          status = BranchMergeObjectStatus.Added;
          rAdded++;
          sourcePaths = r.source_change?.paths || ['/'];
        } else if (!sourceHeadId && targetHeadId) {
          status = BranchMergeObjectStatus.Unchanged;
          rUnchanged++;
          targetPaths = r.target_change?.paths || ['/'];
        } else if (sourceHeadId && targetHeadId) {
          const hashesEqual = (() => {
            const a = r.source_hash as any;
            const b = r.target_hash as any;
            if (!a || !b) return false;
            if (Buffer.isBuffer(a) && Buffer.isBuffer(b))
              return (a as Buffer).equals(b as Buffer);
            return String(a) === String(b);
          })();
          if (hashesEqual) {
            status = BranchMergeObjectStatus.Unchanged;
            rUnchanged++;
          } else {
            sourcePaths = r.source_change?.paths || ['/'];
            targetPaths = r.target_change?.paths || ['/'];
            try {
              const targetProps: Record<string, any> = r.target_props || {};
              const sourceProps: Record<string, any> = r.source_props || {};
              const targetKeys = Object.keys(targetProps);
              const superset = targetKeys.every(
                (k) =>
                  Object.prototype.hasOwnProperty.call(sourceProps, k) &&
                  JSON.stringify(sourceProps[k]) ===
                    JSON.stringify(targetProps[k])
              );
              if (
                superset &&
                Object.keys(sourceProps).some(
                  (k) => !Object.prototype.hasOwnProperty.call(targetProps, k)
                )
              ) {
                status = BranchMergeObjectStatus.FastForward;
                rFF++;
              } else {
                const setA = new Set(sourcePaths);
                const overlap = targetPaths.filter((p: string) => setA.has(p));
                if (overlap.length) {
                  if (sourceIsAncestor) {
                    status = BranchMergeObjectStatus.FastForward;
                    rFF++;
                  } else {
                    status = BranchMergeObjectStatus.Conflict;
                    rConflict++;
                    conflicts = overlap.sort();
                  }
                } else {
                  status = BranchMergeObjectStatus.FastForward;
                  rFF++;
                }
              }
            } catch {
              const setA = new Set(sourcePaths);
              const overlap = targetPaths.filter((p: string) => setA.has(p));
              if (overlap.length) {
                if (sourceIsAncestor) {
                  status = BranchMergeObjectStatus.FastForward;
                  rFF++;
                } else {
                  status = BranchMergeObjectStatus.Conflict;
                  rConflict++;
                  conflicts = overlap.sort();
                }
              } else {
                status = BranchMergeObjectStatus.FastForward;
                rFF++;
              }
            }
          }
        } else {
          continue;
        }
        relationships.push({
          canonical_id: r.canonical_id,
          status,
          source_head_id: sourceHeadId,
          target_head_id: targetHeadId,
          source_paths: sourcePaths,
          target_paths: targetPaths,
          conflicts,
          source_src_id: r.source_src_id || null,
          source_dst_id: r.source_dst_id || null,
          target_src_id: r.target_src_id || null,
          target_dst_id: r.target_dst_id || null,
        });
      }
      // END relationship enumeration
      let applied = false;
      let appliedObjects = 0;
      // Apply phase (Phase 2): if execute requested AND no conflicts -> materialize changes.
      // For Added: copy source head object version into target branch as new independent object (new canonical lineage).
      // For FastForward: copy source head object state into target as new version if object exists, else treat like Added.
      // For Unchanged / Conflict: no action (conflict blocks entire apply).
      if (dto.execute) {
        if (conflict > 0) {
          // Conflicts block merge apply  surface in summary (applied stays false)
        } else {
          // Materialize changes
          for (const o of objects) {
            if (o.status === BranchMergeObjectStatus.Added) {
              appliedObjects++;
              if (o.source_head_id) {
                const srcHead = await this.db.query<any>(
                  `SELECT type, key, properties, labels, project_id FROM kb.graph_objects WHERE id=$1`,
                  [o.source_head_id]
                );
                if (srcHead.rowCount) {
                  const row = srcHead.rows[0];
                  const created = await this.createObject({
                    type: row.type,
                    key: row.key,
                    properties: row.properties,
                    labels: row.labels,
                    project_id: row.project_id,
                    branch_id: targetBranchId,
                  });
                  // Provenance: child <- source (role=source)
                  try {
                    await this.db.query(
                      `INSERT INTO kb.merge_provenance(child_version_id, parent_version_id, role) VALUES ($1,$2,'source') ON CONFLICT DO NOTHING`,
                      [created.id, o.source_head_id]
                    );
                  } catch {
                    /* ignore provenance errors */
                  }
                }
              }
            } else if (o.status === BranchMergeObjectStatus.FastForward) {
              // Fast-forward: integrate non-overlapping changes from source into target as a new version.
              // We intentionally only add properties absent on the target head to avoid accidental overwrite.
              if (o.source_head_id && o.target_head_id) {
                // Attempt merge-base detection (non-blocking)
                let baseVersion: string | null = null;
                try {
                  baseVersion = await this.findMergeBase(
                    o.source_head_id,
                    o.target_head_id
                  );
                } catch {
                  /* swallow */
                }
                const rowsRes = await this.db.query<any>(
                  `SELECT id, type, key, properties FROM kb.graph_objects WHERE id = ANY($1::uuid[])`,
                  [[o.source_head_id, o.target_head_id]]
                );
                const src = rowsRes.rows.find((r) => r.id === o.source_head_id);
                const tgt = rowsRes.rows.find((r) => r.id === o.target_head_id);
                if (src && tgt) {
                  const diff: Record<string, any> = {};
                  for (const [k, v] of Object.entries(src.properties || {})) {
                    if (!(k in (tgt.properties || {}))) diff[k] = v;
                  }
                  if (Object.keys(diff).length) {
                    appliedObjects++;
                    // Patch will create a new version with merged properties
                    const patched = await this.patchObject(o.target_head_id, {
                      properties: diff,
                    } as any);
                    // Provenance: new child version has both prior target and source heads as parents
                    try {
                      if (patched?.id) {
                        await this.db.query(
                          `INSERT INTO kb.merge_provenance(child_version_id, parent_version_id, role) VALUES ($1,$2,'target') ON CONFLICT DO NOTHING`,
                          [patched.id, o.target_head_id]
                        );
                        await this.db.query(
                          `INSERT INTO kb.merge_provenance(child_version_id, parent_version_id, role) VALUES ($1,$2,'source') ON CONFLICT DO NOTHING`,
                          [patched.id, o.source_head_id]
                        );
                        if (baseVersion) {
                          await this.db.query(
                            `INSERT INTO kb.merge_provenance(child_version_id, parent_version_id, role) VALUES ($1,$2,'base') ON CONFLICT DO NOTHING`,
                            [patched.id, baseVersion]
                          );
                        }
                      }
                    } catch {
                      /* provenance non-blocking */
                    }
                  }
                }
              }
            }
          }
          // Apply relationship changes (mirrors object logic) -----------------
          for (const r of relationships) {
            if (r.status === BranchMergeObjectStatus.Added) {
              if (r.source_head_id) {
                const srcHead = await this.db.query<any>(
                  `SELECT type, src_id, dst_id, properties, organization_id, project_id FROM kb.graph_relationships WHERE id=$1`,
                  [r.source_head_id]
                );
                if (srcHead.rowCount) {
                  const row = srcHead.rows[0];
                  // Recreate on target branch as new independent canonical relationship
                  // createRelationship helper not shown; fallback to direct insert
                  try {
                    const createdRel = await this.db.query<{ id: string }>(
                      `INSERT INTO kb.graph_relationships (organization_id, project_id, branch_id, type, src_id, dst_id, properties, labels, version, canonical_id, supersedes_id, change_summary, content_hash)
                                        SELECT $1,$2,$3,$4,$5,$6,$7,'{}',1,gen_random_uuid(),NULL,NULL,NULL
                                        RETURNING id`,
                      [
                        row.organization_id,
                        row.project_id,
                        targetBranchId,
                        row.type,
                        row.src_id,
                        row.dst_id,
                        row.properties || {},
                      ]
                    );
                    if (createdRel.rowCount) {
                      appliedObjects++; // count as an applied change overall
                      try {
                        await this.db.query(
                          `INSERT INTO kb.merge_provenance(child_version_id, parent_version_id, role) VALUES ($1,$2,'source') ON CONFLICT DO NOTHING`,
                          [createdRel.rows[0].id, r.source_head_id]
                        );
                      } catch {
                        /* ignore */
                      }
                    }
                  } catch {
                    /* ignore relationship apply errors */
                  }
                }
              }
            } else if (r.status === BranchMergeObjectStatus.FastForward) {
              if (r.source_head_id && r.target_head_id) {
                let baseVersion: string | null = null;
                try {
                  baseVersion = await this.findMergeBase(
                    r.source_head_id,
                    r.target_head_id
                  );
                } catch {
                  /* swallow */
                }
                const rowsRes = await this.db.query<any>(
                  `SELECT id, properties FROM kb.graph_relationships WHERE id = ANY($1::uuid[])`,
                  [[r.source_head_id, r.target_head_id]]
                );
                const src = rowsRes.rows.find(
                  (rr) => rr.id === r.source_head_id
                );
                const tgt = rowsRes.rows.find(
                  (rr) => rr.id === r.target_head_id
                );
                if (src && tgt) {
                  const diff: Record<string, any> = {};
                  for (const [k, v] of Object.entries(src.properties || {})) {
                    if (!(k in (tgt.properties || {}))) diff[k] = v;
                  }
                  if (Object.keys(diff).length) {
                    try {
                      // Patch target relationship creating a new version (simplified insert-as-new-version pattern)
                      const patched = await this.db.query<{ id: string }>(
                        `INSERT INTO kb.graph_relationships (organization_id, project_id, branch_id, type, src_id, dst_id, properties, labels, version, canonical_id, supersedes_id, change_summary, content_hash)
                                            SELECT organization_id, project_id, branch_id, type, src_id, dst_id, (properties || $2::jsonb), labels, (version + 1), canonical_id, id, NULL, NULL FROM kb.graph_relationships WHERE id=$1 RETURNING id`,
                        [r.target_head_id, diff]
                      );
                      if (patched.rowCount) {
                        appliedObjects++;
                        const newId = patched.rows[0].id;
                        try {
                          await this.db.query(
                            `INSERT INTO kb.merge_provenance(child_version_id, parent_version_id, role) VALUES ($1,$2,'target') ON CONFLICT DO NOTHING`,
                            [newId, r.target_head_id]
                          );
                          await this.db.query(
                            `INSERT INTO kb.merge_provenance(child_version_id, parent_version_id, role) VALUES ($1,$2,'source') ON CONFLICT DO NOTHING`,
                            [newId, r.source_head_id]
                          );
                          if (baseVersion) {
                            await this.db.query(
                              `INSERT INTO kb.merge_provenance(child_version_id, parent_version_id, role) VALUES ($1,$2,'base') ON CONFLICT DO NOTHING`,
                              [newId, baseVersion]
                            );
                          }
                        } catch {
                          /* ignore provenance */
                        }
                      }
                    } catch {
                      /* ignore relationship patch errors */
                    }
                  }
                }
              }
            }
          }
          applied = true;
        }
      }

      const summary: BranchMergeSummaryDto = {
        targetBranchId,
        sourceBranchId,
        dryRun: !dto.execute,
        total_objects: objects.length,
        unchanged_count: unchanged,
        added_count: added,
        fast_forward_count: ff,
        conflict_count: conflict,
        objects,
        truncated: truncated || undefined,
        hard_limit: HARD_LIMIT,
        applied: applied || undefined,
        applied_objects: appliedObjects || undefined,
        relationships_total: relationships.length || undefined,
        relationships_unchanged_count: rUnchanged || undefined,
        relationships_added_count: rAdded || undefined,
        relationships_fast_forward_count: rFF || undefined,
        relationships_conflict_count: rConflict || undefined,
        relationships: relationships.length ? relationships : undefined,
      };

      // Lightweight telemetry/logging (never throws). Mirrors traversal/expand pattern.
      try {
        const evt = {
          type: 'graph.merge.dry_run',
          target_branch: targetBranchId,
          source_branch: sourceBranchId,
          total: summary.total_objects,
          counts: {
            unchanged: summary.unchanged_count,
            added: summary.added_count,
            fast_forward: summary.fast_forward_count,
            conflict: summary.conflict_count,
          },
          truncated: !!summary.truncated,
          hard_limit: summary.hard_limit,
          requested_limit: dto.limit ?? null,
          ts: Date.now(),
        };
        // @ts-ignore internal ad-hoc telemetry bag
        if (!this.telemetry) this.telemetry = { mergeEvents: 0 };
        // @ts-ignore
        this.telemetry.mergeEvents = (this.telemetry.mergeEvents || 0) + 1;
        // @ts-ignore
        this.telemetry.lastMergeDryRun = evt;
        if (process.env.GRAPH_MERGE_TELEMETRY_LOG?.toLowerCase() === 'true') {
          // eslint-disable-next-line no-console
          console.log('[telemetry]', evt);
        }
        // Per-object telemetry (only when reasonably small to avoid noise)
        const objectTelemetry =
          process.env.GRAPH_MERGE_OBJECT_TELEMETRY_LOG?.toLowerCase() ===
          'true';
        const maxObjectEvents = parseInt(
          process.env.GRAPH_MERGE_OBJECT_TELEMETRY_MAX || '50',
          10
        );
        if (objectTelemetry && summary.total_objects <= maxObjectEvents) {
          for (const o of summary.objects) {
            const objEvt = {
              type: 'graph.merge.object',
              target_branch: targetBranchId,
              source_branch: sourceBranchId,
              canonical_id: o.canonical_id,
              status: o.status,
              has_conflicts: !!o.conflicts?.length,
              conflict_paths: o.conflicts,
              ts: Date.now(),
            };
            // @ts-ignore
            this.telemetry.lastMergeObject = objEvt;
            if (
              process.env.GRAPH_MERGE_OBJECT_TELEMETRY_LOG?.toLowerCase() ===
              'true'
            ) {
              // eslint-disable-next-line no-console
              console.log('[telemetry]', objEvt);
            }
          }
        }
      } catch {
        /* swallow */
      }

      return summary;
    });
  }

  private isEmbeddingsEnabled(): boolean {
    const configured = this.config?.embeddingsEnabled ?? false;
    const networkDisabled =
      this.config?.embeddingsNetworkDisabled ??
      Boolean(process.env.EMBEDDINGS_NETWORK_DISABLED);
    return !networkDisabled && configured;
  }
}
