# Commercial Process Definition: Revenue Modeling
# Schema: commercial_definition_schema.json v1.1.0
#
# Rationale for placement: Revenue modeling for fundraising/investor presentations
# belongs in Commercial. The models support investor acquisition, not ongoing 
# financial operations (which belong in OrgOps).

id: cd-014
name: Revenue Modeling
slug: revenue-modeling
track: commercial
status: ready

contributes_to:
  - Commercial.Financial Modeling (for Fundraising).revenue-modeling

maturity:
  current_tier: 1
  
  tier_1_basic:
    description: "Simple revenue projection with key assumptions"
    includes:
      - 12-month revenue forecast in spreadsheet
      - 3-5 key assumptions documented
      - Monthly actuals vs. forecast tracking
      - Basic unit economics (CAC, LTV)
    effort: "1-2 days initial setup, 2 hours/month maintenance"
    
  tier_2_intermediate:
    description: "Scenario-based modeling with drivers"
    adds:
      - Driver-based model (inputs change, outputs recalculate)
      - 3 scenarios (base, optimistic, pessimistic)
      - Cohort-based revenue (monthly cohort retention)
      - 24-month planning horizon
      - Integration with actual financial data
    effort: "1-2 weeks to establish, 4 hours/month ongoing"
    
  tier_3_advanced:
    description: "Comprehensive financial model for fundraising"
    adds:
      - 36-60 month projections
      - Investor-ready financial model
      - Monte Carlo simulation for ranges
      - Cash flow and runway calculations
      - Board-ready reporting package
    effort: "4-6 weeks full implementation"

definition:
  purpose: |
    Revenue modeling answers the question every founder must face: "How will we 
    make money, and how much?" But more importantly, it answers "What has to be 
    true for us to hit our numbers?" A good revenue model is not about predicting 
    the future perfectly - it's about understanding the levers that drive your 
    business and having honest conversations about assumptions.
    
    Revenue models serve multiple audiences:
    - For founders: Decision-making tool for resource allocation
    - For investors: Proof you understand your business mechanics
    - For the team: Clarity on targets and what drives success
    - For the board: Accountability framework for quarterly reviews
    
    Warning signs of a missing or broken revenue model:
    - "We'll figure out revenue later" (deferred business model thinking)
    - Numbers that can't be explained by underlying drivers
    - Actuals consistently miss forecast with no pattern understanding
    - Investor meetings derailed by basic financial questions
    
  outcome: |
    A revenue model that clearly shows how the business makes money, what drives 
    growth, and what needs to be true to hit targets. The model should be a living 
    tool that's updated monthly and used for decision-making, not a one-time 
    artifact created for fundraising.
    
  owner: CEO / CFO / Head of Finance
  
  inputs:
    - name: Historical revenue data
      description: Actual revenue by month, customer, or cohort
      source: Accounting system, billing system
      
    - name: Sales pipeline data
      description: Current pipeline, conversion rates, deal velocity
      source: CRM
      
    - name: Pricing and packaging
      description: Current pricing, plans, upsell paths
      source: Pricing documentation
      
    - name: Customer data
      description: Retention rates, expansion rates, churn patterns
      source: Customer success system, billing data
      
  outputs:
    - name: Revenue model spreadsheet
      description: "Working model with inputs, calculations, and outputs"
      consumer: Leadership, investors, board
      
    - name: Assumptions document
      description: "Key assumptions and their rationale"
      consumer: Internal team, investors during diligence
      
    - name: Scenario analysis
      description: "Base, optimistic, and pessimistic cases"
      consumer: Board, investors

  steps:
    - step: 1
      action: Choose revenue model archetype
      responsible: CEO
      duration: "2-4 hours"
      deliverable: Model structure decision
      revenue_archetypes:
        subscription_saas:
          description: "Recurring revenue with monthly/annual contracts"
          key_drivers: "New MRR, Churn, Expansion, Contraction"
          metric_focus: "ARR, NRR, Logo retention"
          calculation: "Starting MRR + New - Churn - Contraction + Expansion = Ending MRR"
        transactional:
          description: "Revenue per transaction or usage"
          key_drivers: "Active users, Transactions per user, Revenue per transaction"
          metric_focus: "GMV, Take rate, Transaction volume"
          calculation: "Users x Frequency x Value per transaction"
        marketplace:
          description: "Connecting buyers and sellers"
          key_drivers: "Buyers, Sellers, Match rate, GMV, Take rate"
          metric_focus: "GMV, Take rate, Liquidity"
          calculation: "GMV x Take rate"
        services:
          description: "Time or project-based revenue"
          key_drivers: "Billable resources, Utilization, Hourly rate"
          metric_focus: "Revenue per head, Utilization rate"
          calculation: "Resources x Utilization x Rate"
        hybrid:
          description: "Combination of above (e.g., SaaS + marketplace)"
          key_drivers: "Model each stream separately"
          metric_focus: "Contribution by stream"
      best_practices:
        - "Pick the archetype that matches your primary business model"
        - "Hybrid models should model each stream separately, then combine"
        - "Don't overcomplicate - start with primary revenue stream"
      avoid:
        - Trying to model everything at once
        - Picking an archetype because competitors use it
        - Ignoring secondary revenue streams entirely (note them, model later)

    - step: 2
      action: Identify key drivers
      responsible: CEO + Sales Lead
      duration: "Half day"
      deliverable: Driver tree document
      driver_tree_example:
        revenue_goal: "$2M ARR"
        decomposition:
          - driver: Average Contract Value (ACV)
            value: "$20K"
            source: Historical average
          - driver: Deals needed
            value: "100 deals"
            calculation: "$2M / $20K"
          - driver: Close rate
            value: "20 percent"
            source: Historical CRM data
          - driver: Opportunities needed
            value: "500"
            calculation: "100 / 0.20"
          - driver: Leads needed
            value: "2,500"
            assumption: "5x leads to opportunities"
          - driver: Leads per month
            value: "208"
            calculation: "2,500 / 12 months"
      driver_categories:
        top_of_funnel: "Traffic, leads, signups"
        conversion: "Lead-to-opp, opp-to-deal, trial-to-paid"
        monetization: "ACV, pricing, upsell rate"
        retention: "Churn rate, expansion rate, NRR"
        efficiency: "CAC, payback period, LTV:CAC"
      best_practices:
        - "Use historical data where available, estimate conservatively elsewhere"
        - "Each driver should be measurable"
        - "Document where each number comes from"
        - "Flag assumptions vs. known data"
      avoid:
        - Drivers that can't be measured or influenced
        - Overly optimistic assumptions without basis
        - Too many drivers (keep to 5-10 key ones)

    - step: 3
      action: Build the model structure
      responsible: CEO or Finance Lead
      duration: "1-2 days"
      deliverable: Revenue model spreadsheet
      model_structure:
        inputs_tab:
          purpose: "All assumptions in one place"
          contents:
            - "Pricing (ACV, ARPU, pricing tiers)"
            - "Conversion rates (each stage)"
            - "Retention assumptions (churn, expansion)"
            - "Growth assumptions (lead growth, capacity)"
            - "Timing assumptions (sales cycle, ramp)"
        calculations_tab:
          purpose: "Monthly cohort calculations"
          contents:
            - "New customer acquisition (funnel math)"
            - "Revenue recognition (when deals close)"
            - "Churn and expansion (cohort-based)"
            - "Headcount if needed (for capacity)"
        outputs_tab:
          purpose: "Results for review"
          contents:
            - "Monthly revenue (by type: new, expansion, recurring)"
            - "Key metrics (ARR, NRR, CAC, LTV)"
            - "Charts for visualization"
        scenarios_tab:
          purpose: "What-if analysis"
          contents:
            - "Base case (expected)"
            - "Optimistic (upside, stretch goals)"
            - "Pessimistic (downside, planning for worst)"
      formula_principles:
        - "Inputs only in inputs tab, never hard-coded in formulas"
        - "Calculations reference inputs (change input, model recalculates)"
        - "Outputs pull from calculations, never calculate directly"
        - "Scenarios change inputs, not formulas"
      best_practices:
        - "Color code: blue for inputs, black for calculations, green for outputs"
        - "Every number should be traceable to an input or calculation"
        - "Include documentation row explaining each assumption"
        - "Version control (save dated versions before major changes)"

    - step: 4
      action: Model customer cohorts
      responsible: Finance Lead
      duration: "Half day"
      deliverable: Cohort-based revenue calculation
      cohort_concept:
        definition: "Group of customers acquired in the same period (month)"
        why_cohorts: "Different months have different retention patterns"
        calculation: "Track each cohort's revenue over time, then sum all cohorts"
      cohort_model_structure:
        rows: "One row per acquisition month (Jan cohort, Feb cohort, etc.)"
        columns: "Month 1, Month 2, Month 3... for each cohort"
        cells: "Revenue from that cohort in that month"
        total: "Sum column = total revenue in that month from all cohorts"
      retention_modeling:
        logo_retention: "Percentage of customers still paying"
        revenue_retention: "Percentage of revenue retained (can exceed 100 percent with expansion)"
        gross_churn: "Revenue lost from churned customers"
        expansion: "Revenue gained from upgrades, upsells"
        net_revenue_retention: "Gross retention + Expansion (target over 100 percent)"
      best_practices:
        - "Start with logo retention, then layer in revenue dynamics"
        - "Use historical retention curves if available"
        - "Different customer segments may have different retention"
        - "Cohort analysis reveals patterns invisible in aggregate"
      avoid:
        - Assuming flat retention across all cohorts
        - Ignoring seasonality in acquisition or retention
        - Modeling expansion without capacity constraints

    - step: 5
      action: Calculate unit economics
      responsible: CEO + Finance Lead
      duration: "4 hours"
      deliverable: Unit economics summary
      key_metrics:
        cac:
          definition: "Cost to Acquire a Customer"
          calculation: "Total sales and marketing spend / New customers acquired"
          period: "Same period for spend and customers"
          benchmarks: "Varies by industry; lower is better"
        ltv:
          definition: "Lifetime Value of a Customer"
          calculation: "ARPU x Gross Margin x Customer Lifetime"
          lifetime: "1 / Churn Rate (e.g., 5 percent monthly churn = 20 month lifetime)"
          alternative: "Sum of all revenue from cohort over time"
        ltv_cac_ratio:
          definition: "Return on customer acquisition investment"
          healthy: "3x or higher"
          concern: "Below 2x suggests unprofitable acquisition"
          excellent: "5x+ (strong economics)"
        payback_period:
          definition: "Months to recover CAC"
          calculation: "CAC / (ARPU x Gross Margin)"
          healthy: "12 months or less for B2B SaaS"
          excellent: "Under 6 months"
      unit_economics_table:
        format: "One page showing all key metrics"
        includes:
          - "CAC by channel (organic, paid, sales)"
          - "LTV by segment (if different)"
          - "Ratio and payback"
          - "Trend over time"
      best_practices:
        - "Calculate CAC and LTV at segment level if acquisition differs"
        - "Use blended CAC for overall, channel CAC for optimization"
        - "Update quarterly as more data becomes available"
        - "Compare to industry benchmarks for context"

    - step: 6
      action: Create scenario analysis
      responsible: CEO
      duration: "4 hours"
      deliverable: Three scenarios with assumptions
      scenario_framework:
        base_case:
          definition: "What you actually expect to happen"
          how_to_set: "Current trajectory plus realistic improvements"
          probability: "60-70 percent confidence you'll hit or exceed"
        optimistic:
          definition: "Upside scenario if things go well"
          how_to_set: "Base + improvements that are possible but not guaranteed"
          use_case: "Stretch goals, upside planning, investor conversations"
          probability: "20-30 percent chance"
        pessimistic:
          definition: "Downside scenario if things go poorly"
          how_to_set: "Realistic worst case, not catastrophic"
          use_case: "Runway planning, risk management, board contingencies"
          probability: "10-20 percent chance"
      scenario_variables:
        typically_vary:
          - "Lead volume / growth rate"
          - "Conversion rates"
          - "Churn rate"
          - "ACV / pricing"
          - "Hiring pace"
        keep_constant:
          - "Fundamental business model"
          - "Pricing structure"
          - "Core product offering"
      best_practices:
        - "Each scenario should be internally consistent"
        - "Document what would have to be true for each scenario"
        - "Update scenarios quarterly based on actuals"
        - "Use pessimistic for runway calculations"

  cadence:
    frequency: "Monthly update, Quarterly deep review"
    trigger: "Month-end close, board meeting prep, fundraising"
    duration: "2-4 hours monthly, 1 day quarterly"
    ongoing:
      - Update actuals vs. forecast monthly
      - Recalibrate assumptions quarterly
      - Full model review before fundraising
      - Scenario refresh when major changes occur

practitioner_scenarios:
  - id: ps-001
    name: "Founder Building First Revenue Model for Seed Raise"
    practitioner: "CEO / Founder"
    organization_context: |
      Pre-revenue B2B SaaS startup with 3 pilot customers and strong interest 
      from others. Preparing for seed fundraising. No finance background, 
      never built a financial model before.
    situation: |
      Investors are asking "What does your revenue model look like?" and 
      "Walk me through your assumptions." The founder has been focused on 
      product and has rough ideas about pricing but no formal model.
    trigger: |
      VC asked for financial projections before partner meeting. Need to 
      build something credible in the next week.
    actions: |
      1. Started with model archetype: subscription SaaS, simple 
         MRR-based model (new + recurring - churn).
      2. Identified 5 key drivers: lead volume, lead-to-deal conversion, 
         ACV ($15K estimate based on pilot feedback), monthly churn (assumed 
         3 percent based on industry), expansion rate (0 for now).
      3. Built simple spreadsheet: inputs tab with 5 drivers, monthly 
         calculation of new customers and revenue, 24-month output.
      4. Created 3 scenarios by varying conversion rate and lead volume: 
         base case $500K ARR year 1, optimistic $750K, pessimistic $300K.
      5. Added unit economics: estimated CAC of $5K (based on founder time 
         value), LTV of $50K (15K ACV, 3 percent churn), LTV:CAC of 10x.
      6. Documented every assumption with source (pilot feedback, research, 
         or educated guess).
    outcome: |
      Delivered model to investor 5 days later. Investor said: "This is 
      cleaner than most Series A models I see." Questions in partner meeting 
      focused on business, not model mechanics. Raised $2M seed round. Model 
      became the basis for board reporting.
    lessons:
      - Simple, clean models beat complex, confusing ones
      - Documenting assumption sources builds credibility
      - Investors test your thinking through model questions
      - First model becomes foundation for all future planning

  - id: ps-002
    name: "Head of Finance Building Investor-Ready Model for Series A"
    practitioner: "Head of Finance"
    organization_context: |
      25-person B2B SaaS company, $1.5M ARR, 18 months of operating history. 
      Preparing for Series A. Has basic revenue tracking but no cohort-based 
      model or sophisticated projections.
    situation: |
      CEO wants investor-ready financial model with 3-year projections. 
      Current spreadsheets are monthly snapshots, not a driver-based model. 
      Need to demonstrate understanding of unit economics and path to 
      profitability.
    trigger: |
      Board approved Series A timeline. CEO asked for institutional-grade 
      financial model before engaging bankers.
    actions: |
      1. Analyzed 18 months of historical data to establish baselines: 
         actual CAC by channel, retention by cohort, ACV trends.
      2. Built cohort-based model: each month's customers tracked separately 
         through their lifecycle. Revealed that first 6 months of customers 
         had 90 percent retention vs. 75 percent for recent cohorts (red flag).
      3. Created driver-based model: all projections flow from 8 key inputs 
         (lead volume, 3 conversion rates, ACV, churn, expansion, efficiency).
      4. Modeled 36 months with monthly granularity. Added quarterly and 
         annual summary views.
      5. Built 3 scenarios with different hiring and growth assumptions. 
         Base case gets to break-even at month 30.
      6. Created separate tabs for unit economics (with trends), headcount 
         plan, and cash flow. Linked everything to main model.
      7. Added sensitivity analysis: showed impact of 1 percent churn 
         change on year 3 ARR.
    outcome: |
      Model became central to Series A process. Investors praised the 
      clarity and ability to test assumptions. Cohort analysis revealed 
      retention issue that team addressed before fundraising. Raised $12M 
      Series A. Model used for board reporting and hiring planning.
    lessons:
      - Historical cohort analysis reveals truths aggregate data hides
      - Driver-based models let investors test their own assumptions
      - Sensitivity analysis shows you understand what matters
      - Model quality signals operational rigor to investors

  - id: ps-003
    name: "CEO Recalibrating Model After Missing Targets"
    practitioner: "CEO"
    organization_context: |
      40-person B2B company, $4M ARR. Missed revenue target for 3 consecutive 
      quarters. Board is frustrated. Model keeps predicting growth that 
      doesn't materialize. Need to rebuild trust and create realistic plan.
    situation: |
      The current model was built optimistically for fundraising and never 
      recalibrated. It assumes conversion rates and growth that the company 
      hasn't achieved. Board is losing confidence in projections.
    trigger: |
      After third missed quarter, board chair requested full model review 
      and reset. CEO needs to present revised forecast at next board meeting.
    actions: |
      1. Acknowledged model was aspirational, not realistic. Committed to 
         rebuild from actual performance data.
      2. Pulled 12 months of actuals: real conversion rates (15 percent vs. 
         modeled 25 percent), real churn (5 percent vs. modeled 3 percent), 
         real sales cycle (90 days vs. modeled 60 days).
      3. Rebuilt model using only proven metrics. New base case was 40 percent 
         lower than previous forecast.
      4. Created improvement scenarios: showed what happens if conversion 
         improves to 20 percent (with plan to get there), churn drops to 
         4 percent (with initiatives), etc.
      5. Added confidence levels: base case at 80 percent confidence, 
         improvement scenarios at 50 percent.
      6. Built actuals tracking: automated pull of real numbers each month 
         to compare against forecast.
      7. Committed to monthly variance analysis: explain every material 
         difference between forecast and actual.
    outcome: |
      Board meeting was difficult but constructive. Board appreciated 
      honesty and rigor. Approved revised plan with milestones. Hit the 
      new forecast for next 2 quarters (rebuilding trust). Improvement 
      initiatives started to show results. Board confidence restored.
    lessons:
      - Missing forecasts repeatedly destroys trust faster than low forecasts
      - Rebuilding from actuals is painful but necessary
      - Conservative forecasts you hit beat aggressive forecasts you miss
      - Regular variance analysis catches problems early

operational_context:
  prerequisites:
    - At least 3-6 months of historical revenue data (can model without but harder)
    - Access to billing/accounting system data
    - Basic spreadsheet skills
    - Time to think through assumptions
    
  common_blockers:
    - "We don't have enough data - Start with assumptions, refine as data comes"
    - "The model is too complex - Simplify; 5-10 drivers is enough"
    - "Actuals never match forecast - Focus on variance analysis and recalibration"
    - "Investors want different format - Build your model, export their format"
    
  integration_points:
    - Sales: Pipeline data for conversion assumptions
    - Customer Success: Retention and expansion data
    - Finance: Actual revenue and cost data
    - Leadership: Strategic assumptions (pricing, markets, timing)

risks:
  if_skipped: |
    Make decisions without understanding financial implications. Surprise 
    investors with misses. Misallocate resources. Run out of cash 
    unexpectedly. Lose board trust. Fail to identify concerning trends.
    
  if_over_engineered: |
    Spend more time modeling than executing. False precision creates false 
    confidence. Model becomes too complex to maintain. Focus on model 
    mechanics instead of business drivers.

domain_context:
  related_l2: "Financial Structuring"
  related_l1: "FINANCING"
  synergies:
    - "Term Sheet Negotiations (cd-012): Model informs valuation discussions"
    - "Capital Expenditure Planning (cd-015): Revenue funds capex capacity"
    - "Quarterly Reporting (cd-017): Model provides forecast for comparison"
    - "Investor Pitch Decks (cd-010): Model supports financial slides"
